{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- pip install -r requirements.no_faiss.txt\n",
    "- conda install -c conda-forge faiss-cpu -y\n",
    "- python -c \"import faiss; print('faiss ok')\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Ingestion Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LangChain Document Data Structure\n",
    "- page_content (str)\n",
    "    - actual content of the document\n",
    "- metadata (dict)\n",
    "    - additional info about the document\n",
    "    - used for filtering, tracking, and context\n",
    "    - common fields: \n",
    "        - source: file path or URL\n",
    "        - page/chunk id: location in document\n",
    "        - timestamp: creation/modification date\n",
    "        - author: document creator\n",
    "        - category/type: document classification (ex. legal)\n",
    "        - language: content language\n",
    "\n",
    "### Language Document Loaders\n",
    "- PDFLoader (PDF --> Document structure)\n",
    "- CSVLoader\n",
    "- WebBaseLoader \n",
    "- DirectoryLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Document Structure\n",
    "\n",
    "from langchain_core.documents import Document \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python exec: /usr/local/bin/python3\n",
      "Python version: 3.13.2 (v3.13.2:4f8bb3947cf, Feb  4 2025, 11:51:10) [Clang 15.0.0 (clang-1500.3.9.4)]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(\"Python exec:\", sys.executable)\n",
    "print(\"Python version:\", sys.version)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'example.txt', 'pages': 1, 'author': 'Joanna Jung', 'date_created': '20245-01-01'}, page_content='this is the main text content I am using to create RAG')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc=Document(\n",
    "    page_content=\"this is the main text content I am using to create RAG\",\n",
    "    metadata={\n",
    "        \"source\":\"example.txt\",\n",
    "        \"pages\":1,\n",
    "        \"author\":\"Joanna Jung\",\n",
    "        \"date_created\":\"20245-01-01\"\n",
    "    }\n",
    ")\n",
    "\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a simple txt file\n",
    "import os\n",
    "os.makedirs(\"../data/text_files\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample text files created!\n"
     ]
    }
   ],
   "source": [
    "sample_texts={\n",
    "    \"../data/text_files/python_intro.txt\":\"\"\"Python Programming Introduction\n",
    "\n",
    "Python is a high-level, interpreted programming language known for its simplicity and readability.\n",
    "Created by Guido van Rossum and first released in 1991, Python has become one of the most popular\n",
    "programming languages in the world.\n",
    "\n",
    "Key Features:\n",
    "- Easy to learn and use\n",
    "- Extensive standard library\n",
    "- Cross-platform compatibility\n",
    "- Strong community support\n",
    "\n",
    "Python is widely used in web development, data science, artificial intelligence, and automation.\"\"\",\n",
    "    \n",
    "    \"../data/text_files/machine_learning.txt\": \"\"\"Machine Learning Basics\n",
    "\n",
    "Machine learning is a subset of artificial intelligence that enables systems to learn and improve\n",
    "from experience without being explicitly programmed. It focuses on developing computer programs\n",
    "that can access data and use it to learn for themselves.\n",
    "\n",
    "Types of Machine Learning:\n",
    "1. Supervised Learning: Learning with labeled data\n",
    "2. Unsupervised Learning: Finding patterns in unlabeled data\n",
    "3. Reinforcement Learning: Learning through rewards and penalties\n",
    "\n",
    "Applications include image recognition, speech processing, and recommendation systems\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "}\n",
    "\n",
    "for filepath,content in sample_texts.items():\n",
    "    with open(filepath,'w',encoding=\"utf-8\") as f:\n",
    "        f.write(content)\n",
    "\n",
    "print(\"Sample text files created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': '../data/text_files/python_intro.txt'}, page_content='Python Programming Introduction\\n\\nPython is a high-level, interpreted programming language known for its simplicity and readability.\\nCreated by Guido van Rossum and first released in 1991, Python has become one of the most popular\\nprogramming languages in the world.\\n\\nKey Features:\\n- Easy to learn and use\\n- Extensive standard library\\n- Cross-platform compatibility\\n- Strong community support\\n\\nPython is widely used in web development, data science, artificial intelligence, and automation.')]\n"
     ]
    }
   ],
   "source": [
    "### TextLoader - gives txt in Document structure \n",
    "from langchain.document_loaders import TextLoader\n",
    "\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "loader = TextLoader(\"../data/text_files/python_intro.txt\", encoding=\"utf-8\") \n",
    "document = loader.load()\n",
    "print(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': '../data/text_files/python_intro.txt'}, page_content='Python Programming Introduction\\n\\nPython is a high-level, interpreted programming language known for its simplicity and readability.\\nCreated by Guido van Rossum and first released in 1991, Python has become one of the most popular\\nprogramming languages in the world.\\n\\nKey Features:\\n- Easy to learn and use\\n- Extensive standard library\\n- Cross-platform compatibility\\n- Strong community support\\n\\nPython is widely used in web development, data science, artificial intelligence, and automation.'),\n",
       " Document(metadata={'source': '../data/text_files/machine_learning.txt'}, page_content='Machine Learning Basics\\n\\nMachine learning is a subset of artificial intelligence that enables systems to learn and improve\\nfrom experience without being explicitly programmed. It focuses on developing computer programs\\nthat can access data and use it to learn for themselves.\\n\\nTypes of Machine Learning:\\n1. Supervised Learning: Learning with labeled data\\n2. Unsupervised Learning: Finding patterns in unlabeled data\\n3. Reinforcement Learning: Learning through rewards and penalties\\n\\nApplications include image recognition, speech processing, and recommendation systems\\n    \\n    \\n    ')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Directory Loader\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "\n",
    "## load all the text files from the directory\n",
    "dir_loader=DirectoryLoader(\n",
    "    \"../data/text_files\",\n",
    "    glob=\"**/*.txt\", ## Pattern to match files  \n",
    "    loader_cls= TextLoader, ##loader class to use (pdf should be PDFLoader)\n",
    "    loader_kwargs={'encoding': 'utf-8'},\n",
    "    show_progress=False\n",
    "\n",
    ")\n",
    "\n",
    "documents=dir_loader.load()\n",
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'Skia/PDF m144 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/example2.pdf', 'file_path': '../data/pdf/example2.pdf', 'total_pages': 1, 'format': 'PDF 1.4', 'title': 'Github link', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 0}, page_content='https://github.com/Joannaj00/'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2021-01-13T01:34:15+00:00', 'source': '../data/pdf/example.pdf', 'file_path': '../data/pdf/example.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': 'Measuring Massive Multitask Language Understanding', 'author': 'Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, Jacob Steinhardt', 'subject': 'Deep Learning, Transformers, NLP', 'keywords': 'multitask learning, GPT-3, law, bar exam, few-shot learning, zero-shot, meta-learning', 'moddate': '2021-01-13T01:34:15+00:00', 'trapped': '', 'modDate': 'D:20210113013415Z', 'creationDate': 'D:20210113013415Z', 'page': 0}, page_content='Published as a conference paper at ICLR 2021\\nMEASURING MASSIVE MULTITASK\\nLANGUAGE UNDERSTANDING\\nDan Hendrycks\\nUC Berkeley\\nCollin Burns\\nColumbia University\\nSteven Basart\\nUChicago\\nAndy Zou\\nUC Berkeley\\nMantas Mazeika\\nUIUC\\nDawn Song\\nUC Berkeley\\nJacob Steinhardt\\nUC Berkeley\\nABSTRACT\\nWe propose a new test to measure a text model’s multitask accuracy. The test\\ncovers 57 tasks including elementary mathematics, US history, computer science,\\nlaw, and more. To attain high accuracy on this test, models must possess extensive\\nworld knowledge and problem solving ability. We ﬁnd that while most recent\\nmodels have near random-chance accuracy, the very largest GPT-3 model improves\\nover random chance by almost 20 percentage points on average. However, on every\\none of the 57 tasks, the best models still need substantial improvements before\\nthey can reach expert-level accuracy. Models also have lopsided performance\\nand frequently do not know when they are wrong. Worse, they still have near-\\nrandom accuracy on some socially important subjects such as morality and law.\\nBy comprehensively evaluating the breadth and depth of a model’s academic and\\nprofessional understanding, our test can be used to analyze models across many\\ntasks and to identify important shortcomings.\\n1\\nINTRODUCTION\\nNatural Language Processing (NLP) models have achieved superhuman performance on a number of\\nrecently proposed benchmarks. However, these models are still well below human level performance\\nfor language understanding as a whole, suggesting a disconnect between our benchmarks and the\\nactual capabilities of these models. The General Language Understanding Evaluation benchmark\\n(GLUE) (Wang et al., 2018) was introduced in 2018 to evaluate performance on a wide range of NLP\\ntasks, and top models achieved superhuman performance within a year. To address the shortcomings\\nof GLUE, researchers designed the SuperGLUE benchmark with more difﬁcult tasks (Wang et al.,\\n2019). About a year since the release of SuperGLUE, performance is again essentially human-level\\n(Raffel et al., 2019). While these benchmarks evaluate linguistic skills more than overall language\\nunderstanding, an array of commonsense benchmarks have been proposed to measure basic reasoning\\nand everyday knowledge (Zellers et al., 2019; Huang et al., 2019; Bisk et al., 2019). However, these\\nrecent benchmarks have similarly seen rapid progress (Khashabi et al., 2020). Overall, the near\\nhuman-level performance on these benchmarks suggests that they are not capturing important facets\\nof language understanding.\\nTransformer models have driven this recent progress by pretraining on massive text corpora, including\\nall of Wikipedia, thousands of books, and numerous websites. These models consequently see\\nextensive information about specialized topics, most of which is not assessed by existing NLP\\nbenchmarks. It consequently remains an open question just how capable current language models are\\nat learning and applying knowledge from many domains.\\nTo bridge the gap between the wide-ranging knowledge that models see during pretraining and the\\nexisting measures of success, we introduce a new benchmark for assessing models across a diverse\\nset of subjects that humans learn. We design the benchmark to measure knowledge acquired during\\npretraining by evaluating models exclusively in zero-shot and few-shot settings. This makes the\\nbenchmark more challenging and more similar to how we evaluate humans. The benchmark covers\\n57 subjects across STEM, the humanities, the social sciences, and more. It ranges in difﬁculty from\\nan elementary level to an advanced professional level, and it tests both world knowledge and problem\\nsolving ability. Subjects range from traditional areas, such as mathematics and history, to more\\n1\\narXiv:2009.03300v3  [cs.CY]  12 Jan 2021'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2021-01-13T01:34:15+00:00', 'source': '../data/pdf/example.pdf', 'file_path': '../data/pdf/example.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': 'Measuring Massive Multitask Language Understanding', 'author': 'Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, Jacob Steinhardt', 'subject': 'Deep Learning, Transformers, NLP', 'keywords': 'multitask learning, GPT-3, law, bar exam, few-shot learning, zero-shot, meta-learning', 'moddate': '2021-01-13T01:34:15+00:00', 'trapped': '', 'modDate': 'D:20210113013415Z', 'creationDate': 'D:20210113013415Z', 'page': 1}, page_content='Published as a conference paper at ICLR 2021\\nFew Shot Prompt and Predicted Answer\\nHow many numbers are in the list 25, 26, ..., 100?\\n(A) 75 (B) 76 (C) 22 (D) 23\\nAnswer: B\\nCompute i + i2+ i3+ ··· + i 258+ i259.\\n(A) -1 (B) 1 (C) i (D) -i\\nAnswer: A\\nIf 4 daps = 7 yaps, and 5 yaps = 3 baps,\\nhow many daps equal 42 baps?\\n(A) 28 (B) 21 (C) 40 (D) 30\\nAnswer: C␣\\nThe following are multiple choice questions\\nabout high school mathematics.\\n(a) An example of few-shot learning and inference us-\\ning GPT-3. The blue underlined bold text is the auto-\\ncompleted response from GPT-3, while the preceding\\ntext is the user-inputted prompt. In this 2-shot learning\\nexample, there are two instruction examples and one\\ninitially incomplete example. On average, GPT-3 has\\nlow accuracy on high school mathematics questions.\\nSmall\\nMedium\\nLarge\\nX-Large\\nModel Size\\n20\\n30\\n40\\n50\\n60\\n70\\n80\\n90\\nPerformance (%)\\nGPT-3 Few Shot Test Performance\\nCommonsense\\nLinguistics\\nKnowledge (Ours)\\n(b) Performance on a commonsense benchmark (Hel-\\nlaSwag), a linguistic understanding benchmark (Super-\\nGLUE), and the massive multitask test. On previous\\nbenchmarks, smaller models start well above random\\nchance levels and exhibit more continuous improve-\\nments with model size increases, but on our test, GPT-3\\nmoves beyond random chance with the largest model.\\nspecialized areas like law and ethics (Hendrycks et al., 2020). The granularity and breadth of the\\nsubjects makes the benchmark ideal for identifying a model’s blind spots.\\nWe ﬁnd that meaningful progress on our benchmark has only become possible in recent months. In\\nparticular, few-shot models up to 13 billion parameters (Brown et al., 2020) achieve random chance\\nperformance of 25% accuracy, but the 175 billion parameter GPT-3 model reaches a much higher\\n43.9% accuracy (see Figure 1b). On the other hand, unlike human professionals GPT-3 does not\\nexcel at any single subject. Instead, we ﬁnd that performance is lopsided, with GPT-3 having almost\\n70% accuracy for its best subject but near-random performance for several other subjects.\\nOur results indicate that while recent advances have been impressive, state-of-the-art models still\\nstruggle at learning and applying knowledge from pretraining. The tasks with near-random accuracy\\ninclude calculation-heavy subjects such as physics and mathematics and subjects related to human\\nvalues such as law and morality. This second weakness is particularly concerning because it will\\nbe important for future models to have a strong understanding of what is legal and what is ethical.\\nWorryingly, we also ﬁnd that GPT-3 does not have an accurate sense of what it does or does not know\\nsince its average conﬁdence can be up to 24% off from its actual accuracy. We comprehensively\\nevaluate the breadth and depth of a model’s text understanding by covering numerous topics that\\nhumans are incentivized to learn. Since our test consists in 57 tasks, it can be used to analyze\\naggregate properties of models across tasks and to track important shortcomings. The test and code is\\navailable at github.com/hendrycks/test.\\n2\\nRELATED WORK\\nPretraining.\\nThe dominant paradigm in NLP is to pretrain large models on massive text corpora\\nincluding educational books and websites. In the process, these models are exposed to information\\nabout a wide range of topics. Petroni et al. (2019) found that recent models learn enough information\\nfrom pretraining that they can serve as knowledge bases. However, no prior work has comprehensively\\nmeasured the knowledge models have across many real-world domains.\\nUntil recently, researchers primarily used ﬁne-tuned models on downstream tasks (Devlin et al., 2019).\\nHowever, larger pretrained models like GPT-3 (Brown et al., 2020) have made it possible to achieve\\ncompetitive performance without ﬁne-tuning by using few-shot learning, which removes the need for\\na large ﬁne-tuning set. With the advent of strong zero-shot and few-shot learning, it is now possible\\nto curate a diverse set of tasks for evaluation and remove the possibility of models on “spurious cues”\\n(Geirhos et al., 2020; Hendrycks et al., 2019b) in a dataset to achieve high performance.\\nBenchmarks.\\nMany recent benchmarks aim to assess a model’s general world knowledge and basic\\nreasoning ability by testing its “commonsense.” A number of commonsense benchmarks have been\\n2'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2021-01-13T01:34:15+00:00', 'source': '../data/pdf/example.pdf', 'file_path': '../data/pdf/example.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': 'Measuring Massive Multitask Language Understanding', 'author': 'Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, Jacob Steinhardt', 'subject': 'Deep Learning, Transformers, NLP', 'keywords': 'multitask learning, GPT-3, law, bar exam, few-shot learning, zero-shot, meta-learning', 'moddate': '2021-01-13T01:34:15+00:00', 'trapped': '', 'modDate': 'D:20210113013415Z', 'creationDate': 'D:20210113013415Z', 'page': 2}, page_content='Published as a conference paper at ICLR 2021\\nAs Seller, an encyclopedia salesman, approached the grounds on which Hermit\\'s house was situated,\\nhe saw a sign that said, \"No salesmen. Trespassers will be prosecuted. Proceed at your own risk.\"\\nAlthough Seller had not been invited to enter, he ignored the sign and drove up the driveway toward\\nthe house. As he rounded a curve, a powerful explosive charge buried in the driveway exploded, and\\nSeller was injured. Can Seller recover damages from Hermit for his injuries?\\n(A) Yes, unless Hermit, when he planted the charge, intended only to deter, not harm, intruders.\\n(B) Yes, if Hermit was responsible for the explosive charge under the driveway.\\n(C) No, because Seller ignored the sign, which warned him against proceeding further.\\n(D) No, if Hermit reasonably feared that intruders would come and harm him or his family.\\nProfessional Law\\nFigure 2: This task requires understanding detailed and dissonant scenarios, applying appropriate\\nlegal precedents, and choosing the correct explanation. The green checkmark is the ground truth.\\nproposed in the past year, but recent models are already nearing human-level performance on several\\nof these, including HellaSwag (Zellers et al., 2019), Physical IQA (Bisk et al., 2019), and CosmosQA\\n(Huang et al., 2019). By design, these datasets assess abilities that almost every child has. In contrast,\\nwe include harder specialized subjects that people must study to learn.\\nSome researchers have suggested that the future of NLP evaluation should focus on Natural Language\\nGeneration (NLG) (Zellers et al., 2020), an idea that reaches back to the Turing Test (Turing, 1950).\\nHowever, NLG is notoriously difﬁcult to evaluate and lacks a standard metric (Sai et al., 2020).\\nConsequently, we instead create a simple-to-evaluate test that measures classiﬁcation accuracy on\\nmultiple choice questions.\\nWhile several question answering benchmarks exist, they are comparatively limited in scope. Most\\neither cover easy topics like grade school subjects for which models can already achieve strong\\nperformance (Clark et al., 2018; Khot et al., 2019; Mihaylov et al., 2018; Clark et al., 2019), or\\nare focused on linguistic understanding in the form of reading comprehension (Lai et al., 2017;\\nRichardson et al., 2013). In contrast, we include a wide range of difﬁcult subjects that go far beyond\\nlinguistic understanding.\\n3\\nA MULTITASK TEST\\nWe create a massive multitask test consisting of multiple-choice questions from various branches of\\nknowledge. The test spans subjects in the humanities, social sciences, hard sciences, and other areas\\nthat are important for some people to learn. There are 57 tasks in total, which is also the number\\nof Atari games (Bellemare et al., 2013), all of which are listed in Appendix B. The questions in\\nthe dataset were manually collected by graduate and undergraduate students from freely available\\nsources online. These include practice questions for tests such as the Graduate Record Examination\\nand the United States Medical Licensing Examination. It also includes questions designed for\\nundergraduate courses and questions designed for readers of Oxford University Press books. Some\\ntasks cover a subject, like psychology, but at a speciﬁc level of difﬁculty, such as “Elementary,”\\n“High School,” “College,” or “Professional.” For example, the “Professional Psychology” task draws\\non questions from freely available practice questions for the Examination for Professional Practice\\nin Psychology, while the “High School Psychology” task has questions like those from Advanced\\nPlacement Psychology examinations.\\nWe collected 15908 questions in total, which we split into a few-shot development set, a validation\\nset, and a test set. The few-shot development set has 5 questions per subject, the validation set may\\nbe used for selecting hyperparameters and is made of 1540 questions, and the test set has 14079\\nquestions. Each subject contains 100 test examples at the minimum, which is longer than most exams\\ndesigned to assess people.\\nHuman-level accuracy on this test varies. Unspecialized humans from Amazon Mechanical Turk\\nobtain 34.5% accuracy on this test. Meanwhile, expert-level performance can be far higher. For\\nexample, real-world test-taker human accuracy at the 95th percentile is around 87% for US Medical\\nLicensing Examinations, and these questions make up our “Professional Medicine” task. If we take\\nthe 95th percentile human test-taker accuracy for exams that build up our test, and if we make an\\neducated guess when such information is unavailable, we then estimate that expert-level accuracy is\\napproximately 89.8%.\\nSince our test aggregates different subjects and several levels of difﬁculty, we measure more than\\nstraightforward commonsense or narrow linguistic understanding. Instead, we measure arbitrary\\n3'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2021-01-13T01:34:15+00:00', 'source': '../data/pdf/example.pdf', 'file_path': '../data/pdf/example.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': 'Measuring Massive Multitask Language Understanding', 'author': 'Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, Jacob Steinhardt', 'subject': 'Deep Learning, Transformers, NLP', 'keywords': 'multitask learning, GPT-3, law, bar exam, few-shot learning, zero-shot, meta-learning', 'moddate': '2021-01-13T01:34:15+00:00', 'trapped': '', 'modDate': 'D:20210113013415Z', 'creationDate': 'D:20210113013415Z', 'page': 3}, page_content='Published as a conference paper at ICLR 2021\\nOne of the reasons that the government discourages and regulates monopolies is that\\n(A) producer surplus is lost and consumer surplus is gained.\\n(B) monopoly prices ensure productive efficiency but cost society allocative efficiency.\\n(C) monopoly firms do not engage in significant research and development.\\n(D) consumer surplus is lost with higher prices and lower levels of output.\\nMicroeconomics\\nFigure 3: Examples from the Microeconomics task.\\nWhen you drop a ball from rest it accelerates downward at 9.8 m/s². If you instead throw it\\ndownward assuming no air resistance its acceleration immediately after leaving your hand is\\n(A) 9.8 m/s²\\n(B) more than 9.8 m/s²\\n(C) less than 9.8 m/s²\\n(D) Cannot say unless the speed of throw is given.\\nConceptual\\nPhysics\\nCollege\\nMathematics\\nIn the complex z-plane, the set of points satisfying the equation z² = |z|² is a\\n(A) pair of points\\n(B) circle\\n(C) half-line\\n(D) line\\nFigure 4: Examples from the Conceptual Physics and College Mathematics STEM tasks.\\nreal-world text understanding. Since models are pretrained on the Internet, this enables us to test\\nhow well they can extract useful knowledge from massive corpora. Future models that use this test\\ncould be single models or a mixture of experts model. To succeed at our test, future models should be\\nwell-rounded, possess extensive world knowledge, and develop expert-level problem solving ability.\\nThese properties make the test likely to be an enduring and informative goalpost.\\n3.1\\nHUMANITIES\\nThe humanities is a group of disciplines that make use of qualitative analysis and analytic methods\\nrather than scientiﬁc empirical methods. Branches of the humanities include law, philosophy, history,\\nand so on (Appendix B). Mastering these subjects requires a variety of skills. For example, legal\\nunderstanding requires knowledge of how to apply rules and standards to complex scenarios, and\\nalso provide answers with stipulations and explanations. We illustrate this in Figure 2. Legal\\nunderstanding is also necessary for understanding and following rules and regulations, a necessary\\ncapability to constrain open-world machine learning models. For philosophy, our questions cover\\nconcepts like logical fallacies, formal logic, and famous philosophical arguments. It also covers\\nmoral scenarios, including questions from the ETHICS dataset (Hendrycks et al., 2020) that test a\\nmodel’s understanding of normative statements through predicting widespread moral intuitions about\\ndiverse everyday scenarios. Finally, our history questions cover a wide range of time periods and\\ngeographical locations, including prehistory and other advanced subjects.\\n3.2\\nSOCIAL SCIENCE\\nSocial science includes branches of knowledge that examine human behavior and society. Subject\\nareas include economics, sociology, politics, geography, psychology, and so on. See Figure 3 for\\nan example question. Our economics questions include microeconomics, macroeconomics, and\\neconometrics, and cover different types of problems, including questions that require a mixture of\\nworld knowledge, qualitative reasoning, or quantitative reasoning. We also include important but\\nmore esoteric topics such as security studies in order to test the boundaries of what is experienced and\\nlearned during pretraining. Social science also includes psychology, a ﬁeld that may be especially\\nimportant for attaining a nuanced understanding of humans.\\n3.3\\nSCIENCE, TECHNOLOGY, ENGINEERING, AND MATHEMATICS (STEM)\\nSTEM subjects include physics, computer science, mathematics, and more. Two examples are shown\\nin Figure 4. Conceptual physics tests understanding of simple physics principles and may be thought\\n4'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2021-01-13T01:34:15+00:00', 'source': '../data/pdf/example.pdf', 'file_path': '../data/pdf/example.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': 'Measuring Massive Multitask Language Understanding', 'author': 'Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, Jacob Steinhardt', 'subject': 'Deep Learning, Transformers, NLP', 'keywords': 'multitask learning, GPT-3, law, bar exam, few-shot learning, zero-shot, meta-learning', 'moddate': '2021-01-13T01:34:15+00:00', 'trapped': '', 'modDate': 'D:20210113013415Z', 'creationDate': 'D:20210113013415Z', 'page': 4}, page_content='Published as a conference paper at ICLR 2021\\nA 33-year-old man undergoes a radical thyroidectomy for thyroid cancer. During the operation,\\nmoderate hemorrhaging requires ligation of several vessels in the left side of the neck.\\nPostoperatively, serum studies show a calcium concentration of 7.5 mg/dL, albumin concentration\\nof 4 g/dL, and parathyroid hormone concentration of 200 pg/mL. Damage to which of the following\\nvessels caused the findings in this patient?\\n(A) Branch of the costocervical trunk\\n(B) Branch of the external carotid artery\\n(C) Branch of the thyrocervical trunk\\n(D) Tributary of the internal jugular vein\\nProfessional Medicine\\nFigure 5: A question from the Professional Medicine task.\\nof as a harder version of the physical commonsense benchmark Physical IQA (Bisk et al., 2019). We\\nalso test mathematical problem solving ability at various levels of difﬁculty, from the elementary to\\nthe college level. College mathematics questions, like those found on the GRE mathematics subject\\ntest, often require chains of reasoning and abstract knowledge. To encode mathematics expressions,\\nwe use LaTeX or symbols such as * and ˆ for multiplication and exponentiation respectively. STEM\\nsubjects require knowledge of empirical methods, ﬂuid intelligence, and procedural knowledge.\\n3.4\\nOTHER\\nThere is a long tail of subjects that either do not neatly ﬁt into any of the three preceding categories or\\nfor which there are not thousands of freely available questions. We put these subjects into Other. This\\nsection includes the Professional Medicine task, which has difﬁcult questions that require humans\\nmany years of study to master. An example is depicted in Figure 5. This section also contains\\nbusiness topics like ﬁnance, accounting, and marketing, as well as knowledge of global facts. The\\nlatter includes statistics about poverty in different countries over time, which may be necessary for\\nhaving an accurate model of the world internationally.\\n4\\nEXPERIMENTS\\n4.1\\nSETUP\\nAssessment and Models.\\nTo measure performance on our multitask test, we compute the clas-\\nsiﬁcation accuracy across all examples and tasks. We evaluate GPT-3 (Brown et al., 2020) and\\nUniﬁedQA (Khashabi et al., 2020). For GPT-3 we use the OpenAI API, which provides access to four\\nmodel variants, “Ada,” “Babbage,” “Curie,” and “Davinci,” which we refer to as “Small” (2.7 billion\\nparameters), “Medium” (6.7 billion), “Large” (13 billion) and “X-Large” (175 billion). UniﬁedQA\\nuses the T5 (Raffel et al., 2019) text-to-text backbone and is ﬁne-tuned on previously proposed\\nquestion answering datasets (Lai et al., 2017), where the prediction is the class with the highest\\ntoken overlap with UniﬁedQA’s text output. Since UniﬁedQA is ﬁne-tuned on other datasets, we\\nevaluate it without any further tuning to assess its transfer accuracy. We also ﬁne-tune RoBERTa-base,\\nALBERT-xxlarge, and GPT-2 on UniﬁedQA training data and our dev+val set. We primarily focus on\\nUniﬁedQA and GPT-3 in the rest of this document, but additional discussion of RoBERTa, ALBERT,\\nand GPT-2 is in Appendix A.\\nModel\\nHumanities\\nSocial Science\\nSTEM\\nOther\\nAverage\\nRandom Baseline\\n25.0\\n25.0\\n25.0\\n25.0\\n25.0\\nRoBERTa\\n27.9\\n28.8\\n27.0\\n27.7\\n27.9\\nALBERT\\n27.2\\n25.7\\n27.7\\n27.9\\n27.1\\nGPT-2\\n32.8\\n33.3\\n30.2\\n33.1\\n32.4\\nUniﬁedQA\\n45.6\\n56.6\\n40.2\\n54.6\\n48.9\\nGPT-3 Small (few-shot)\\n24.4\\n30.9\\n26.0\\n24.1\\n25.9\\nGPT-3 Medium (few-shot)\\n26.1\\n21.6\\n25.6\\n25.5\\n24.9\\nGPT-3 Large (few-shot)\\n27.1\\n25.6\\n24.3\\n26.5\\n26.0\\nGPT-3 X-Large (few-shot)\\n40.8\\n50.4\\n36.7\\n48.8\\n43.9\\nTable 1: Average weighted accuracy for each model on all four broad disciplines. All values are\\npercentages. Some models proposed in the past few months can move several percent points beyond\\nrandom chance. GPT-3 uses few-shot learning and UniﬁedQA is tested under distribution shift.\\n5'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2021-01-13T01:34:15+00:00', 'source': '../data/pdf/example.pdf', 'file_path': '../data/pdf/example.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': 'Measuring Massive Multitask Language Understanding', 'author': 'Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, Jacob Steinhardt', 'subject': 'Deep Learning, Transformers, NLP', 'keywords': 'multitask learning, GPT-3, law, bar exam, few-shot learning, zero-shot, meta-learning', 'moddate': '2021-01-13T01:34:15+00:00', 'trapped': '', 'modDate': 'D:20210113013415Z', 'creationDate': 'D:20210113013415Z', 'page': 5}, page_content=\"Published as a conference paper at ICLR 2021\\n0\\n20\\n40\\n60\\n80\\n100\\nAccuracy (%)\\nWorld Religions\\nVirology\\nUS Foreign Policy\\nSociology\\nSecurity Studies\\nPublic Relations\\nProfessional Psychology\\nProfessional Medicine\\nProfessional Law\\nProfessional Accounting\\nPrehistory\\nPhilosophy\\nNutrition\\nMoral Scenarios\\nMoral Disputes\\nMiscellaneous\\nMedical Genetics\\nMarketing\\nManagement\\nMachine Learning\\nLogical Fallacies\\nJurisprudence\\nInternational Law\\nHuman Sexuality\\nHuman Aging\\nHigh School World History\\nHigh School US History\\nHigh School Statistics\\nHigh School Psychology\\nHigh School Physics\\nHigh School Microeconomics\\nHigh School Mathematics\\nHigh School Macroeconomics\\nHigh School Gov't and Politics\\nHigh School Geography\\nHigh School European History\\nHigh School Comp Sci\\nHigh School Chemistry\\nHigh School Biology\\nGlobal Facts\\nFormal Logic\\nElementary Mathematics\\nElectrical Engineering\\nEconometrics\\nConceptual Physics\\nComputer Security\\nCollege Physics\\nCollege Medicine\\nCollege Mathematics\\nCollege Comp Sci\\nCollege Chemistry\\nCollege Biology\\nClinical Knowledge\\nBusiness Ethics\\nAstronomy\\nAnatomy\\nAbstract Algebra\\nGPT-3\\nUnifiedQA\\nRandom\\nFigure 6: GPT-3 (few-shot) and UniﬁedQA results.\\nFew-Shot Prompt.\\nWe feed GPT-3 prompts\\nlike that shown in Figure 1a. We begin each\\nprompt with “The following are multiple choice\\nquestions (with answers) about [subject].” For\\nzero-shot evaluation, we append the question to\\nthe prompt. For few-shot evaluation, we add up\\nto 5 demonstration examples with answers to\\nthe prompt before appending the question. All\\nprompts end with “Answer: ”. The model then\\nproduces probabilities for the tokens “A,” “B,”\\n“C,” and “D,” and we treat the highest probability\\noption as the prediction. For consistent evalua-\\ntion, we create a dev set with 5 ﬁxed few-shot\\nexamples for each subject.\\n4.2\\nRESULTS\\nModel Size and Accuracy.\\nWe compare the\\nfew-shot accuracy of each GPT-3 size in Table 1.\\nWe ﬁnd that the three smaller GPT-3 models\\nhave near random accuracy (around 25%). In\\ncontrast, we ﬁnd that the X-Large 175 billion\\nparameter GPT-3 model performs substantially\\nbetter than random, with an accuracy of 43.9%.\\nWe also ﬁnd qualitatively similar results in the\\nzero-shot setting. While the smaller models\\nhave around 25% zero-shot accuracy, Figure 10\\nin Appendix A shows that the largest GPT-3\\nmodel has a much higher zero-shot accuracy of\\nabout 37.7%. Brown et al. (2020) also observe\\nthat larger GPT-3 models perform better, though\\nprogress tends to be steadier. In Figure 1b we\\nshow that non-random accuracy on the multitask\\ntest emerged with recent large few-shot models\\ncompared to datasets that assess commonsense\\nand linguistic understanding.\\nTo test the usefulness of ﬁne-tuning instead of\\nfew-shot learning, we also evaluate UniﬁedQA\\nmodels. UniﬁedQA has the advantage of being\\nﬁne-tuned on other question answering datasets,\\nunlike GPT-3. We assess UniﬁedQA by evalu-\\nating its transfer performance without any ad-\\nditional ﬁne-tuning.\\nThe largest UniﬁedQA\\nmodel we test has 11 billion parameters, which\\nis slightly smaller than GPT-3 Large. Neverthe-\\nless, we show in Table 1 that it attains 48.9%\\naccuracy. This performs better than the few-shot GPT-3 X-Large model, despite UniﬁedQA have\\nan order of magnitude fewer parameters. We also ﬁnd that even the smallest UniﬁedQA variant,\\nwith just 60 million parameters, has approximately 29.3% accuracy. These results suggest that while\\nmodel size is a key component for achieving strong performance, ﬁne-tuning also helps.\\nComparing Disciplines.\\nUsing our test, we discover that GPT-3 and UniﬁedQA have lopsided\\nperformance and several substantial knowledge gaps. Figure 6 shows the accuracy of GPT-3 (few-\\nshot) and UniﬁedQA for all 57 tasks. It shows the both models are below expert-level performance\\nfor all tasks, with GPT-3’s accuracy ranging from 69% for US Foreign Policy to 26% for College\\nChemistry. UniﬁedQA does best on marketing, with an accuracy of 82.5%.\\nOverall, models do poorly on highly procedural problems. Figure 6 shows that calculation-heavy\\nSTEM subjects tend to have low accuracy compared to verbal subjects. For GPT-3, 9 out of the 10\\n6\"),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2021-01-13T01:34:15+00:00', 'source': '../data/pdf/example.pdf', 'file_path': '../data/pdf/example.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': 'Measuring Massive Multitask Language Understanding', 'author': 'Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, Jacob Steinhardt', 'subject': 'Deep Learning, Transformers, NLP', 'keywords': 'multitask learning, GPT-3, law, bar exam, few-shot learning, zero-shot, meta-learning', 'moddate': '2021-01-13T01:34:15+00:00', 'trapped': '', 'modDate': 'D:20210113013415Z', 'creationDate': 'D:20210113013415Z', 'page': 6}, page_content='Published as a conference paper at ICLR 2021\\nDeclarative vs. Procedural Knowledge\\nPrompt and Completion:\\nThe order of operations or PEMDAS is\\nParentheses Exponents Multiplication\\nDivision Addition Subtraction\\nPrompt and Completion:\\n(1 + 1) × 2 = 3␣\\nFigure 7: GPT-3’s completion for two prompts\\ntesting knowledge of the order of operations. The\\nblue underlined bold text is the autocompleted\\nresponse from GPT-3. While it knows about the\\norder of operations, it sometimes does not know\\nhow to apply its knowledge.\\n20\\n30\\n40\\n50\\n60\\nConfidence (%)\\n20\\n30\\n40\\n50\\n60\\nAccuracy (%)\\nGPT-3 Zero-Shot Calibration\\nFormal Logic\\nMarketing\\nFigure 8: GPT-3’s conﬁdence is a poor estimator\\nof its accuracy and can be off by up to 24%.\\nlowest-accuracy tasks are STEM subjects that emphasize mathematics or calculations. We speculate\\nthat is in part because GPT-3 acquires declarative knowledge more readily than procedural knowledge.\\nFor example, many questions in Elementary Mathematics require applying the order of operations\\nfor arithmetic, which is described by the acronym PEMDAS (Parentheses Exponents Multiplication\\nDivision Addition Subtraction). In Figure 7, we conﬁrm that GPT-3 is aware of the acronym\\nPEMDAS. However, it does not consistently apply PEMDAS to actual problems. On the other hand,\\nprocedural understanding is not its only weak point. We ﬁnd that some verbal tasks such as Moral\\nScenarios from Hendrycks et al. (2020) and Professional Law also have especially low accuracy.\\nOur test also shows that GPT-3 acquires knowledge quite unlike humans. For example, GPT-3 learns\\nabout topics in a pedagogically unusual order. GPT-3 does better on College Medicine (47.4%)\\nand College Mathematics (35.0%) than calculation-heavy Elementary Mathematics (29.9%). GPT-3\\ndemonstrates unusual breadth, but it does not master a single subject. Meanhwhile we suspect humans\\nhave mastery in several subjects but not as much breadth. In this way, our test shows that GPT-3 has\\nmany knowledge blindspots and has capabilities that are lopsided.\\nCalibration.\\nWe should not trust a model’s prediction unless the model is calibrated, meaning\\nthat its conﬁdence is a good estimate of the actual probability the prediction is correct. However,\\nlarge neural networks are often miscalibrated (Guo et al., 2017), especially under distribution shift\\n(Ovadia et al., 2019). We evaluate the calibration of GPT-3 by testing how well its average conﬁdence\\nestimates its actual accuracy for each subject. We show the results in Figure 8, which demonstrates\\nthat GPT-3 is uncalibrated. In fact, its conﬁdence is only weakly related to its actual accuracy in\\nthe zero-shot setting, with the difference between its accuracy and conﬁdence reaching up to 24%\\nfor some subjects. Another calibration measure is the Root Mean Squared (RMS) calibration error\\n(Hendrycks et al., 2019a; Kumar et al., 2019). Many tasks have miscalibrated predictions, such as\\nElementary Mathematics which has a zero-shot RMS calibration error of 19.4%. Models are only\\nsomewhat more calibrated in the few-shot setting, as shown in Appendix A. These results suggest\\nthat model calibration has wide room for improvement.\\n5\\nDISCUSSION\\nMultimodal Understanding.\\nWhile text is capable of conveying an enormous number of concepts\\nabout the world, many important concepts are conveyed mainly through other modalities, such as\\nimages, audio, and physical interaction (Bisk et al., 2020). Existing large-scale NLP models, such as\\nGPT-3, do not incorporate multimodal information, so we design our benchmark to capture a diverse\\narray of tasks in a text-only format. However, as models gain the ability to process multimodal inputs,\\nbenchmarks should be designed to reﬂect this change. One such benchmark could be a “Turk Test,”\\nconsisting of Amazon Mechanical Turk Human Intelligence Tasks. These are well-deﬁned tasks that\\nrequire models to interact with ﬂexible formats and demonstrate multimodal understanding.\\nThe Internet as a Training Set.\\nA major distinction between our benchmark and previous multitask\\nNLP benchmarks is that we do not require large training sets. Instead, we assume that models have\\nacquired the requisite knowledge from reading vast quantities of diverse text from the Internet. This\\n7'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2021-01-13T01:34:15+00:00', 'source': '../data/pdf/example.pdf', 'file_path': '../data/pdf/example.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': 'Measuring Massive Multitask Language Understanding', 'author': 'Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, Jacob Steinhardt', 'subject': 'Deep Learning, Transformers, NLP', 'keywords': 'multitask learning, GPT-3, law, bar exam, few-shot learning, zero-shot, meta-learning', 'moddate': '2021-01-13T01:34:15+00:00', 'trapped': '', 'modDate': 'D:20210113013415Z', 'creationDate': 'D:20210113013415Z', 'page': 7}, page_content='Published as a conference paper at ICLR 2021\\nprocess is typically called pretraining, but it can be thought of as training in its own right, where the\\ndownstream evaluation is demonstrating whatever knowledge we would expect a human to pick up\\nfrom reading the same text.\\nThis motivates us to propose a methodological change so that models are trained more like how\\nhumans learn. While most previous machine learning benchmarks have models learn from a large\\nquestion bank, humans primarily learn new subjects by reading books and listening to others talk\\nabout the topic. For specialized subjects such as Professional Law, massive legal corpora are available,\\nsuch as the 164-volume legal encyclopedia Corpus Juris Secundum, but there are fewer than 5,000\\nmultistate bar exam questions available. Learning the entire law exclusively through a small number\\nof practice tests is implausible, so future models must learn more during pretraining.\\nFor this reason we assess pretrained models in a zero-shot, few-shot, or transfer setting and we provide\\na dev, val, and test set for each task. The dev set is used for few-shot prompts, the val set could be\\nused for hyperparameter tuning, and the test set is used to compute the ﬁnal accuracy. Importantly,\\nthe format of our evaluation is not identical to the format in which information is acquired during\\npretraining. This has the beneﬁt of obviating concerns about spurious training set annotation artifacts\\n(Geirhos et al., 2020; Hendrycks et al., 2019b) and is in stark contrast to the previous paradigm\\nof identically distributed training and test sets. This change also enables collecting a much more\\nextensive and diverse set of tasks for evaluation. We anticipate our methodology becoming more\\nwidespread as models improve at extracting information from diverse online sources.\\nModel Limitations.\\nWe ﬁnd that current large-scale Transformers have wide room for improvement.\\nThey are notably poor at modeling human (dis)approval, as evident by the low performance on the\\nProfessional Law and Moral Scenarios tasks. For future systems to be aligned with human values, high\\nperformance on these tasks is crucial (Hendrycks et al., 2020), so future research should especially\\naim to increase accuracy on these tasks. Models also have difﬁculty performing calculations, so much\\nso that they exhibit poor performance on Elementary Mathematics and many other STEM subjects\\nwith “plug and chug” problems. Additionally, they do not match expert-level performance (90%) on\\nany subject, so for all subjects it is subhuman. On average, models are only now starting to move\\nbeyond random-chance accuracy levels.\\nAddressing these shortcomings may be challenging. To illustrate this, we attempted to create a better\\nProfessional Law model by pretraining on specialized data but achieved only limited success. We\\ncollected approximately 2,000 additional Professional Law training examples. After ﬁne-tuning a\\nRoBERTa-base model (Liu et al., 2019) using this custom training set, our model attained 32.8% test\\naccuracy. To test the impact of additional specialized training data, we also had RoBERTa continue\\npretraining on approximately 1.6 million legal case summaries using Harvard’s Law Library case law\\ncorpus case.law, but after ﬁne-tuning it only attained 36.1% accuracy. This suggests that while\\nadditional pretraining on relevant high quality text can help, it may not be enough to substantially\\nincrease the performance of current models.\\nIt is unclear whether simply scaling up existing language models will solve the test. Current\\nunderstanding indicates that a 10× increase in model size must be accompanied by an approximate\\n5× increase in data (Kaplan et al., 2020). Aside from the tremendous expense in creating multi-trillion\\nparameter language models, data may also become a bottleneck, as there is far less written about\\nesoteric branches of knowledge than about everyday situations.\\n6\\nCONCLUSION\\nWe introduced a new test that measures how well text models can learn and apply knowledge\\nencountered during pretraining. By covering 57 subjects at varying levels of difﬁculty, the test\\nassesses language understanding in greater breadth and depth than previous benchmarks. We found\\nthat it has recently become possible for models to make meaningful progress on the test, but that\\nstate-of-the-art models have lopsided performance and rarely excel at any individual task. We also\\nshowed that current models are uncalibrated and have difﬁculty with tasks that require calculations.\\nWorryingly, models also perform especially poorly on socially relevant subjects including morality\\nand law. Our expansive test can help researchers pinpoint important shortcomings of models, making\\nit easier to gain a clearer picture of state-of-the-art capabilities.\\n8'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2021-01-13T01:34:15+00:00', 'source': '../data/pdf/example.pdf', 'file_path': '../data/pdf/example.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': 'Measuring Massive Multitask Language Understanding', 'author': 'Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, Jacob Steinhardt', 'subject': 'Deep Learning, Transformers, NLP', 'keywords': 'multitask learning, GPT-3, law, bar exam, few-shot learning, zero-shot, meta-learning', 'moddate': '2021-01-13T01:34:15+00:00', 'trapped': '', 'modDate': 'D:20210113013415Z', 'creationDate': 'D:20210113013415Z', 'page': 8}, page_content='Published as a conference paper at ICLR 2021\\nACKNOWLEDGEMENTS\\nWe would like to thank the following for their helpful comments: Oyvind Tafjord, Jan Leike, David\\nKrueger, Alex Tamkin, Girish Sastry, and Henry Zhu. DH is supported by the NSF GRFP Fellowship\\nand an Open Philanthropy Project Fellowship. This research was also supported by the NSF Frontier\\nAward 1804794.\\nREFERENCES\\nM. G. Bellemare, Y. Naddaf, J. Veness, and M. Bowling. The arcade learning environment: An\\nevaluation platform for general agents (extended abstract). J. Artif. Intell. Res., 47:253–279, 2013.\\nY. Bisk, R. Zellers, R. L. Bras, J. Gao, and Y. Choi. Piqa: Reasoning about physical commonsense in\\nnatural language, 2019.\\nY. Bisk, A. Holtzman, J. Thomason, J. Andreas, Y. Bengio, J. Chai, M. Lapata, A. Lazaridou, J. May,\\nA. Nisnevich, N. Pinto, and J. Turian. Experience grounds language, 2020.\\nT. B. Brown, B. Mann, N. Ryder, M. Subbiah, J. Kaplan, P. Dhariwal, A. Neelakantan, P. Shyam,\\nG. Sastry, A. Askell, S. Agarwal, A. Herbert-Voss, G. Krueger, T. Henighan, R. Child, A. Ramesh,\\nD. M. Ziegler, J. Wu, C. Winter, C. Hesse, M. Chen, E. Sigler, M. Litwin, S. Gray, B. Chess,\\nJ. Clark, C. Berner, S. McCandlish, A. Radford, I. Sutskever, and D. Amodei. Language models\\nare few-shot learners, 2020.\\nP. Clark, I. Cowhey, O. Etzioni, T. Khot, A. Sabharwal, C. Schoenick, and O. Tafjord. Think you have\\nsolved question answering? try arc, the ai2 reasoning challenge. ArXiv, abs/1803.05457, 2018.\\nP. Clark, O. Etzioni, D. Khashabi, T. Khot, B. D. Mishra, K. Richardson, A. Sabharwal, C. Schoenick,\\nO. Tafjord, N. Tandon, S. Bhakthavatsalam, D. Groeneveld, M. Guerquin, and M. Schmitz. From ’f’\\nto ’a’ on the n.y. regents science exams: An overview of the aristo project. ArXiv, abs/1909.01958,\\n2019.\\nJ. Devlin, M.-W. Chang, K. Lee, and K. Toutanova.\\nBert: Pre-training of deep bidirectional\\ntransformers for language understanding. ArXiv, abs/1810.04805, 2019.\\nR. Geirhos, J.-H. Jacobsen, C. Michaelis, R. Zemel, W. Brendel, M. Bethge, and F. A. Wichmann.\\nShortcut learning in deep neural networks, 2020.\\nC. Guo, G. Pleiss, Y. Sun, and K. Q. Weinberger. On calibration of modern neural networks. ICML,\\n2017.\\nD. Hendrycks, M. Mazeika, and T. Dietterich. Deep anomaly detection with outlier exposure. ICLR,\\n2019a.\\nD. Hendrycks, K. Zhao, S. Basart, J. Steinhardt, and D. Song. Natural adversarial examples. ArXiv,\\nabs/1907.07174, 2019b.\\nD. Hendrycks, C. Burns, S. Basart, A. Critch, J. Li, D. Song, and J. Steinhardt. Aligning ai with\\nshared human values, 2020.\\nL. Huang, R. L. Bras, C. Bhagavatula, and Y. Choi. Cosmos qa: Machine reading comprehension\\nwith contextual commonsense reasoning, 2019.\\nJ. Kaplan, S. McCandlish, T. Henighan, T. B. Brown, B. Chess, R. Child, S. Gray, A. Radford, J. Wu,\\nand D. Amodei. Scaling laws for neural language models, 2020.\\nD. Khashabi, T. Khot, A. Sabharwal, O. Tafjord, P. Clark, and H. Hajishirzi. Uniﬁedqa: Crossing\\nformat boundaries with a single qa system, 2020.\\nT. Khot, P. Clark, M. Guerquin, P. Jansen, and A. Sabharwal. Qasc: A dataset for question answering\\nvia sentence composition, 2019.\\nA. Kumar, P. Liang, and T. Ma. Veriﬁed uncertainty calibration, 2019.\\n9'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2021-01-13T01:34:15+00:00', 'source': '../data/pdf/example.pdf', 'file_path': '../data/pdf/example.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': 'Measuring Massive Multitask Language Understanding', 'author': 'Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, Jacob Steinhardt', 'subject': 'Deep Learning, Transformers, NLP', 'keywords': 'multitask learning, GPT-3, law, bar exam, few-shot learning, zero-shot, meta-learning', 'moddate': '2021-01-13T01:34:15+00:00', 'trapped': '', 'modDate': 'D:20210113013415Z', 'creationDate': 'D:20210113013415Z', 'page': 9}, page_content='Published as a conference paper at ICLR 2021\\nG. Lai, Q. Xie, H. Liu, Y. Yang, and E. Hovy. Race: Large-scale reading comprehension dataset from\\nexaminations, 2017.\\nZ. Lan, M. Chen, S. Goodman, K. Gimpel, P. Sharma, and R. Soricut. Albert: A lite bert for\\nself-supervised learning of language representations. ArXiv, abs/1909.11942, 2020.\\nY. Liu, M. Ott, N. Goyal, J. Du, M. Joshi, D. Chen, O. Levy, M. Lewis, L. Zettlemoyer, and\\nV. Stoyanov. Roberta: A robustly optimized bert pretraining approach. ArXiv, abs/1907.11692,\\n2019.\\nT. Mihaylov, P. Clark, T. Khot, and A. Sabharwal. Can a suit of armor conduct electricity? a new\\ndataset for open book question answering. In EMNLP, 2018.\\nY. Ovadia, E. Fertig, J. Ren, Z. Nado, D. Sculley, S. Nowozin, J. V. Dillon, B. Lakshminarayanan,\\nand J. Snoek. Can you trust your model’s uncertainty? Evaluating predictive uncertainty under\\ndataset shift. NeurIPS, 2019.\\nF. Petroni, T. Rocktäschel, P. Lewis, A. Bakhtin, Y. Wu, A. H. Miller, and S. Riedel. Language\\nmodels as knowledge bases?, 2019.\\nA. Radford, J. Wu, R. Child, D. Luan, D. Amodei, and I. Sutskever. Language models are unsupervised\\nmultitask learners. 2019.\\nC. Raffel, N. Shazeer, A. Roberts, K. Lee, S. Narang, M. Matena, Y. Zhou, W. Li, and P. J. Liu.\\nExploring the limits of transfer learning with a uniﬁed text-to-text transformer, 2019.\\nM. Richardson, C. J. Burges, and E. Renshaw. MCTest: A challenge dataset for the open-domain\\nmachine comprehension of text. In Proceedings of the 2013 Conference on Empirical Methods in\\nNatural Language Processing, pages 193–203, Seattle, Washington, USA, Oct. 2013. Association\\nfor Computational Linguistics.\\nA. B. Sai, A. K. Mohankumar, and M. M. Khapra. A survey of evaluation metrics used for nlg\\nsystems. 2020.\\nA. Turing. Computing machinery and intelligence. 1950.\\nA. Wang, A. Singh, J. Michael, F. Hill, O. Levy, and S. R. Bowman. Glue: A multi-task benchmark\\nand analysis platform for natural language understanding, 2018.\\nA. Wang, Y. Pruksachatkun, N. Nangia, A. Singh, J. Michael, F. Hill, O. Levy, and S. R. Bowman.\\nSuperglue: A stickier benchmark for general-purpose language understanding systems, 2019.\\nR. Zellers, A. Holtzman, Y. Bisk, A. Farhadi, and Y. Choi. Hellaswag: Can a machine really ﬁnish\\nyour sentence?, 2019.\\nR. Zellers, A. Holtzman, E. Clark, L. Qin, A. Farhadi, and Y. Choi. Evaluating machines by their\\nreal-world language use, 2020.\\n10'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2021-01-13T01:34:15+00:00', 'source': '../data/pdf/example.pdf', 'file_path': '../data/pdf/example.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': 'Measuring Massive Multitask Language Understanding', 'author': 'Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, Jacob Steinhardt', 'subject': 'Deep Learning, Transformers, NLP', 'keywords': 'multitask learning, GPT-3, law, bar exam, few-shot learning, zero-shot, meta-learning', 'moddate': '2021-01-13T01:34:15+00:00', 'trapped': '', 'modDate': 'D:20210113013415Z', 'creationDate': 'D:20210113013415Z', 'page': 10}, page_content=\"Published as a conference paper at ICLR 2021\\nA\\nADDITIONAL ANALYSIS\\nThis appendix includes ﬁgures with sorted results (Figure 9), few-shot examples vs. accuracy\\n(Figure 10), and few-shot calibration (Figure 11). It also includes sections on ﬁne-tuning, error\\nanalysis, and format sensitivity.\\n0\\n20\\n40\\n60\\n80\\n100\\nAccuracy (%)\\nCollege Chemistry\\nMoral Scenarios\\nCollege Physics\\nHigh School Physics\\nHigh School Mathematics\\nFormal Logic\\nElementary Mathematics\\nAbstract Algebra\\nHigh School Statistics\\nMachine Learning\\nEconometrics\\nHigh School Chemistry\\nProfessional Accounting\\nProfessional Law\\nCollege Mathematics\\nProfessional Medicine\\nConceptual Physics\\nGlobal Facts\\nHigh School Comp Sci\\nMedical Genetics\\nHigh School Macroeconomics\\nHigh School Microeconomics\\nMoral Disputes\\nProfessional Psychology\\nCollege Biology\\nVirology\\nCollege Comp Sci\\nBusiness Ethics\\nNutrition\\nCollege Medicine\\nAnatomy\\nClinical Knowledge\\nLogical Fallacies\\nHigh School Biology\\nPublic Relations\\nAstronomy\\nElectrical Engineering\\nHuman Aging\\nPhilosophy\\nSecurity Studies\\nPrehistory\\nHigh School US History\\nSociology\\nHigh School European History\\nHuman Sexuality\\nJurisprudence\\nWorld Religions\\nInternational Law\\nHigh School World History\\nManagement\\nComputer Security\\nHigh School Geography\\nHigh School Gov't and Politics\\nMarketing\\nMiscellaneous\\nHigh School Psychology\\nUS Foreign Policy\\nGPT-3 Results\\nRandom Chance\\n0\\n10\\n20\\n30\\n40\\n50\\n60\\n70\\n80\\n90 100\\nAccuracy (%)\\nMoral Scenarios\\nFormal Logic\\nAbstract Algebra\\nEconometrics\\nHigh School Mathematics\\nCollege Physics\\nMachine Learning\\nHigh School Statistics\\nCollege Chemistry\\nElementary Mathematics\\nCollege Mathematics\\nHigh School Chemistry\\nGlobal Facts\\nProfessional Law\\nMedical Genetics\\nProfessional Accounting\\nCollege Biology\\nHigh School Physics\\nAnatomy\\nCollege Comp Sci\\nConceptual Physics\\nCollege Medicine\\nVirology\\nProfessional Medicine\\nAstronomy\\nHigh School Macroeconomics\\nElectrical Engineering\\nProfessional Psychology\\nSecurity Studies\\nHuman Sexuality\\nNutrition\\nHigh School Comp Sci\\nPrehistory\\nClinical Knowledge\\nHigh School Biology\\nHuman Aging\\nHigh School Microeconomics\\nPhilosophy\\nPublic Relations\\nWorld Religions\\nMoral Disputes\\nLogical Fallacies\\nHigh School European History\\nHigh School US History\\nHigh School World History\\nMiscellaneous\\nUS Foreign Policy\\nComputer Security\\nSociology\\nInternational Law\\nHigh School Geography\\nJurisprudence\\nBusiness Ethics\\nHigh School Psychology\\nManagement\\nHigh School Gov't and Politics\\nMarketing\\nUnifiedQA Results\\nRandom Chance\\nFigure 9: On the left are GPT-3 few shot accuracies for all of the 57 tasks. On the right are UniﬁedQA\\ntransfer accuracies for all of the 57 tasks. For both models, capabilities are lopsided.\\nA.1\\nANALYSIS WITH MORE FINE-TUNED MODELS\\nWe primarily analyzed models with more than 10 billion parameters in the main body of the paper.\\nFor this section, we analyze smaller models including RoBERTa-base (125 million parameters) (Liu\\n11\"),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2021-01-13T01:34:15+00:00', 'source': '../data/pdf/example.pdf', 'file_path': '../data/pdf/example.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': 'Measuring Massive Multitask Language Understanding', 'author': 'Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, Jacob Steinhardt', 'subject': 'Deep Learning, Transformers, NLP', 'keywords': 'multitask learning, GPT-3, law, bar exam, few-shot learning, zero-shot, meta-learning', 'moddate': '2021-01-13T01:34:15+00:00', 'trapped': '', 'modDate': 'D:20210113013415Z', 'creationDate': 'D:20210113013415Z', 'page': 11}, page_content='Published as a conference paper at ICLR 2021\\net al., 2019), ALBERT-xxlarge (223 million parameters) (Lan et al., 2020), and GPT-2 (1,558 million\\nparameters) (Radford et al., 2019). Models are ﬁne-tuned to predict one of four classes using the\\nUniﬁedQA MCQ questions and using our dev+val set. We test on our multitask test set.\\nWe observe that these smaller models can attain better-than-random accuracy. RoBERTa-base attains\\nan overall accuracy of 27.9%, with 27.9% accuracy for the humanities, 28.8% for social sciences,\\n27.0% for STEM, and 27.7% for other. ALBERT-xxlarge attains an accuracy of 27.1%, with 27.2%\\naccuracy for the humanities, 25.7% for the social sciences, 27.7% for STEM, and 27.9% for other.\\nGPT-2 attains an accuracy of 32.4%, with 32.8% accuracy for the humanities, 33.3% for the social\\nsciences, 30.2% for STEM, and 33.1% for other.\\nCompare this to UniﬁedQA’s smallest variant, which has just 60 million parameters and approximately\\n29.3% accuracy. It obtains higher accuracy than RoBERTa and ALBERT, even though it has fewer\\nparameters. This suggests that its larger pretraining dataset enables higher accuracy. Likewise,\\nUniﬁedQA with 3 billion parameters attains 43.7%, while the similarly sized GPT-2 model with 1.5\\nbillion parameters attains 32.4% accuracy. This again suggests that T5’s larger pretraining dataset\\nsize (and therefore UniﬁedQA’s pretraining dataset size) can increase accuracy.\\nA.2\\nERROR ANALYSIS\\nWe qualitatively analyze when GPT-3 makes high conﬁdence mistakes. We ﬁnd that while many of\\nthese mistakes were clearly wrong, many were mistakes that a human might make. For example,\\none question it got wrong was “How many chromosomes do all human somatic cells contain?” The\\ncorrect answer is 46, while few-shot GPT-3 predicted 23 with conﬁdence 97.5%. This answer would\\nhave been correct if the question asked about the number of pairs of chromosomes. Similarly, many\\nof its other high conﬁdence mistakes were also correct answers to slightly different questions.\\nA.3\\nFORMAT SENSITIVITY\\nWhile different question formatting choices often lead to similar GPT-3 accuracies, we ﬁnd that\\nUniﬁedQA is more sensitive. UniﬁedQA’s input format is of the form\\nQUESTION1 \\\\\\\\n (A) CHOICE1 (B) CHOICE2 (C) CHOICE3 (D) CHOICE4</s>\\nwhere questions and choices are normalized and made lowercase. If we remove the </s> from the\\ninput, accuracy declines by several percentage points.\\n12'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2021-01-13T01:34:15+00:00', 'source': '../data/pdf/example.pdf', 'file_path': '../data/pdf/example.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': 'Measuring Massive Multitask Language Understanding', 'author': 'Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, Jacob Steinhardt', 'subject': 'Deep Learning, Transformers, NLP', 'keywords': 'multitask learning, GPT-3, law, bar exam, few-shot learning, zero-shot, meta-learning', 'moddate': '2021-01-13T01:34:15+00:00', 'trapped': '', 'modDate': 'D:20210113013415Z', 'creationDate': 'D:20210113013415Z', 'page': 12}, page_content='Published as a conference paper at ICLR 2021\\n0-Shot 1-Shot 2-Shot 3-Shot 4-Shot 5-Shot\\nNumber of Examples in Context\\n30\\n35\\n40\\n45\\n50\\nAccuracy (%)\\nGPT-3 Multitask Accuracy vs.\\nNumber of Examples in Context\\nFigure 10: As the number of few-shot instruction\\nexamples increases, the accuracy monotonically\\nincreases. Notably, zero-shot performance is only\\nsomewhat lower than 5-shot accuracy.\\n20\\n30\\n40\\n50\\n60\\n70\\nConfidence (%)\\n20\\n30\\n40\\n50\\n60\\n70\\nAccuracy (%)\\nGPT-3 Few-Shot Calibration\\nFigure 11: While models are more calibrated in\\na few-shot setting than a zero-shot setting, they\\nare still miscalibrated, with gap between accuracy\\nand conﬁdence reaching up to 14%. Here the\\ncorrelation between conﬁdence and accuracy is\\nr = 0.81, compared to r = 0.63 in the zero-shot\\nsetting.\\nB\\nTEST DETAILS\\nB.1\\nTASK DESCRIPTIONS AND EXAMPLES\\nWe provide analysis of question length and difﬁculty in Figure 12. We list all tasks and the topics\\nthey test in Table 2. We also provide an example for each task starting with Figure 14.\\n0\\n500\\n1000\\n1500\\n2000\\n2500\\n3000\\nQuestion Length (Characters)\\n0.0\\n0.2\\n0.4\\n0.6\\n0.8\\n1.0\\nConfidence of True Label\\nGPT-3 Question Length and Correctness\\n0\\n250\\n500\\n750\\n1000\\n1250\\nAverage Question Length (Characters)\\n0.0\\n0.2\\n0.4\\n0.6\\n0.8\\n1.0\\nSubject Accuracy\\nGPT-3 Average Question Length and\\nAccuracy by Subject\\nFigure 12: Figures on the relation between question difﬁculty and question length. For questions\\nlonger than a tweet (280 characters), the correlation between question length and true label conﬁdence\\nis slightly positive. This shows that longer questions are not necessarily harder.\\nB.2\\nEXACT QUESTION AND ANSWER CONTAMINATION\\nSince language models train on vast text corpora, there is some chance that they have seen the exact\\nquestion and answer during pretraining. If they memorized the exact question and answer, then\\nthey would attain higher accuracy than their true ability. Likewise, a question’s entropy would be\\nespecially low if it were memorized. Memorized questions and answers should have low entropy and\\n13'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2021-01-13T01:34:15+00:00', 'source': '../data/pdf/example.pdf', 'file_path': '../data/pdf/example.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': 'Measuring Massive Multitask Language Understanding', 'author': 'Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, Jacob Steinhardt', 'subject': 'Deep Learning, Transformers, NLP', 'keywords': 'multitask learning, GPT-3, law, bar exam, few-shot learning, zero-shot, meta-learning', 'moddate': '2021-01-13T01:34:15+00:00', 'trapped': '', 'modDate': 'D:20210113013415Z', 'creationDate': 'D:20210113013415Z', 'page': 13}, page_content='Published as a conference paper at ICLR 2021\\nhigh accuracy. However, in Figure 13, we see that accuracy and question entropy are not positively\\ncorrelated, suggesting that the test’s low-entropy questions do not correspond to memorized (and\\nthereby correctly predicted) answers. This suggests that our exact questions were not memorized.\\nHowever, during pretraining models encountered text related to our questions through processing\\nWikipedia. We also note that most of our questions came from PDFs or websites where questions and\\nanswers are on separate pages.\\nSee Brown et al. (2020) for a previous discussion of contamination showing that the phenomena\\nhardly affects performance. To reduce the probability that future models encounter exact questions\\nduring test-time, we will provide a list of question sources.\\n2.8\\n2.6\\n2.4\\n2.2\\n2.0\\n1.8\\nLog Probability Per Token\\n20\\n30\\n40\\n50\\n60\\nAccuracy (%)\\nGPT-3 Zero-Shot\\nPrompt Compression and Accuracy\\n2.4\\n2.2\\n2.0\\n1.8\\n1.6\\n1.4\\n1.2\\nLog Probability Per Token\\n20\\n30\\n40\\n50\\n60\\n70\\nAccuracy (%)\\nGPT-3 Few-Shot\\nPrompt Compression and Accuracy\\nFigure 13: The average log probability of the question (without answer) is not strongly positively\\ncorrelated with accuracy, all else equal. Each point corresponds to a task. Higher log probability\\nindicates higher compression, and especially high log probability would suggest memorization. In\\nthe zero-shot question prompt, the correlation between average log probability and accuracy is\\nr = −0.43, and for the few-shot setting the correlation is r = −0.56.\\n14'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2021-01-13T01:34:15+00:00', 'source': '../data/pdf/example.pdf', 'file_path': '../data/pdf/example.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': 'Measuring Massive Multitask Language Understanding', 'author': 'Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, Jacob Steinhardt', 'subject': 'Deep Learning, Transformers, NLP', 'keywords': 'multitask learning, GPT-3, law, bar exam, few-shot learning, zero-shot, meta-learning', 'moddate': '2021-01-13T01:34:15+00:00', 'trapped': '', 'modDate': 'D:20210113013415Z', 'creationDate': 'D:20210113013415Z', 'page': 14}, page_content='Published as a conference paper at ICLR 2021\\nTask\\nTested Concepts\\nSupercategory\\nAbstract Algebra\\nGroups, rings, ﬁelds, vector spaces, ...\\nSTEM\\nAnatomy\\nCentral nervous system, circulatory system, ...\\nSTEM\\nAstronomy\\nSolar system, galaxies, asteroids, ...\\nSTEM\\nBusiness Ethics\\nCorporate responsibility, stakeholders, regulation, ...\\nOther\\nClinical Knowledge\\nSpot diagnosis, joints, abdominal examination, ...\\nOther\\nCollege Biology\\nCellular structure, molecular biology, ecology, ...\\nSTEM\\nCollege Chemistry\\nAnalytical, organic, inorganic, physical, ...\\nSTEM\\nCollege Computer Science\\nAlgorithms, systems, graphs, recursion, ...\\nSTEM\\nCollege Mathematics\\nDifferential equations, real analysis, combinatorics, ...\\nSTEM\\nCollege Medicine\\nIntroductory biochemistry, sociology, reasoning, ...\\nOther\\nCollege Physics\\nElectromagnetism, thermodynamics, special relativity, ...\\nSTEM\\nComputer Security\\nCryptography, malware, side channels, fuzzing, ...\\nSTEM\\nConceptual Physics\\nNewton’s laws, rotational motion, gravity, sound, ...\\nSTEM\\nEconometrics\\nVolatility, long-run relationships, forecasting, ...\\nSocial Sciences\\nElectrical Engineering\\nCircuits, power systems, electrical drives, ...\\nSTEM\\nElementary Mathematics\\nWord problems, multiplication, remainders, rounding, ...\\nSTEM\\nFormal Logic\\nPropositions, predicate logic, ﬁrst-order logic, ...\\nHumanities\\nGlobal Facts\\nExtreme poverty, literacy rates, life expectancy, ...\\nOther\\nHigh School Biology\\nNatural selection, heredity, cell cycle, Krebs cycle, ...\\nSTEM\\nHigh School Chemistry\\nChemical reactions, ions, acids and bases, ...\\nSTEM\\nHigh School Computer Science\\nArrays, conditionals, iteration, inheritance, ...\\nSTEM\\nHigh School European History\\nRenaissance, reformation, industrialization, ...\\nHumanities\\nHigh School Geography\\nPopulation migration, rural land-use, urban processes, ...\\nSocial Sciences\\nHigh School Gov’t and Politics\\nBranches of government, civil liberties, political ideologies, ...\\nSocial Sciences\\nHigh School Macroeconomics\\nEconomic indicators, national income, international trade, ...\\nSocial Sciences\\nHigh School Mathematics\\nPre-algebra, algebra, trigonometry, calculus, ...\\nSTEM\\nHigh School Microeconomics\\nSupply and demand, imperfect competition, market failure, ...\\nSocial Sciences\\nHigh School Physics\\nKinematics, energy, torque, ﬂuid pressure, ...\\nSTEM\\nHigh School Psychology\\nBehavior, personality, emotions, learning, ...\\nSocial Sciences\\nHigh School Statistics\\nRandom variables, sampling distributions, chi-square tests, ...\\nSTEM\\nHigh School US History\\nCivil War, the Great Depression, The Great Society, ...\\nHumanities\\nHigh School World History\\nOttoman empire, economic imperialism, World War I, ...\\nHumanities\\nHuman Aging\\nSenescence, dementia, longevity, personality changes, ...\\nOther\\nHuman Sexuality\\nPregnancy, sexual differentiation, sexual orientation, ...\\nSocial Sciences\\nInternational Law\\nHuman rights, sovereignty, law of the sea, use of force, ...\\nHumanities\\nJurisprudence\\nNatural law, classical legal positivism, legal realism, ...\\nHumanities\\nLogical Fallacies\\nNo true Scotsman, base rate fallacy, composition fallacy, ...\\nHumanities\\nMachine Learning\\nSVMs, VC dimension, deep learning architectures, ...\\nSTEM\\nManagement\\nOrganizing, communication, organizational structure, ...\\nOther\\nMarketing\\nSegmentation, pricing, market research, ...\\nOther\\nMedical Genetics\\nGenes and cancer, common chromosome disorders, ...\\nOther\\nMiscellaneous\\nAgriculture, Fermi estimation, pop culture, ...\\nOther\\nMoral Disputes\\nFreedom of speech, addiction, the death penalty, ...\\nHumanities\\nMoral Scenarios\\nDetecting physical violence, stealing, externalities, ...\\nHumanities\\nNutrition\\nMetabolism, water-soluble vitamins, diabetes, ...\\nOther\\nPhilosophy\\nSkepticism, phronesis, skepticism, Singer’s Drowning Child, ...\\nHumanities\\nPrehistory\\nNeanderthals, Mesoamerica, extinction, stone tools, ...\\nHumanities\\nProfessional Accounting\\nAuditing, reporting, regulation, valuation, ...\\nOther\\nProfessional Law\\nTorts, criminal law, contracts, property, evidence, ...\\nHumanities\\nProfessional Medicine\\nDiagnosis, pharmacotherapy, disease prevention, ...\\nOther\\nProfessional Psychology\\nDiagnosis, biology and behavior, lifespan development, ...\\nSocial Sciences\\nPublic Relations\\nMedia theory, crisis management, intelligence gathering, ...\\nSocial Sciences\\nSecurity Studies\\nEnvironmental security, terrorism, weapons of mass destruction, ...\\nSocial Sciences\\nSociology\\nSocialization, cities and community, inequality and wealth, ...\\nSocial Sciences\\nUS Foreign Policy\\nSoft power, Cold War foreign policy, isolationism, ...\\nSocial Sciences\\nVirology\\nEpidemiology, coronaviruses, retroviruses, herpesviruses, ...\\nOther\\nWorld Religions\\nJudaism, Christianity, Islam, Buddhism, Jainism, ...\\nHumanities\\nTable 2: Summary of all 57 tasks.\\n15'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2021-01-13T01:34:15+00:00', 'source': '../data/pdf/example.pdf', 'file_path': '../data/pdf/example.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': 'Measuring Massive Multitask Language Understanding', 'author': 'Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, Jacob Steinhardt', 'subject': 'Deep Learning, Transformers, NLP', 'keywords': 'multitask learning, GPT-3, law, bar exam, few-shot learning, zero-shot, meta-learning', 'moddate': '2021-01-13T01:34:15+00:00', 'trapped': '', 'modDate': 'D:20210113013415Z', 'creationDate': 'D:20210113013415Z', 'page': 15}, page_content='Published as a conference paper at ICLR 2021\\nFind all c in Z3 such that Z3[x]/(x2 + c) is a ﬁeld.\\n(A) 0\\n(B) 1\\n(C) 2\\n(D) 3\\nFigure 14: An Abstract Algebra example.\\nWhat is the embryological origin of the hyoid bone?\\n(A) The ﬁrst pharyngeal arch\\n(B) The ﬁrst and second pharyngeal arches\\n(C) The second pharyngeal arch\\n(D) The second and third pharyngeal arches\\nFigure 15: An Anatomy example.\\nWhy isn’t there a planet where the asteroid belt is located?\\n(A) A planet once formed here but it was broken apart by a catastrophic collision.\\n(B) There was not enough material in this part of the solar nebula to form a planet.\\n(C) There was too much rocky material to form a terrestrial planet but not enough gaseous material\\nto form a jovian planet.\\n(D) Resonance with Jupiter prevented material from collecting together to form a planet.\\nFigure 16: An Astronomy example.\\nThree contrasting tactics that CSO’s can engage in to meet their aims are\\nwhich typi-\\ncally involves research and communication,\\n, which may involve physically attacking a\\ncompany’s operations or\\n, often involving some form of\\n.\\n(A) Non-violent direct action, Violent direct action, Indirect action, Boycott\\n(B) Indirect action, Instrumental action, Non-violent direct action, Information campaign\\n(C) Indirect action, Violent direct action, Non-violent direct-action Boycott.\\n(D) Non-violent direct action, Instrumental action, Indirect action, Information campaign\\nFigure 17: A Business Ethics example.\\nHow many attempts should you make to cannulate a patient before passing the job on to a senior\\ncolleague?\\n(A) 4\\n(B) 3\\n(C) 2\\n(D) 1\\nFigure 18: A Clinical Knowledge example.\\nIn a given population, 1 out of every 400 people has a cancer caused by a completely recessive\\nallele, b. Assuming the population is in Hardy-Weinberg equilibrium, which of the following is\\nthe expected proportion of individuals who carry the b allele but are not expected to develop the\\ncancer?\\n(A) 1/400\\n(B) 19/400\\n(C) 20/400\\n(D) 38/400\\nFigure 19: A College Biology example.\\nWhich of the following statements about the lanthanide elements is NOT true?\\n(A) The most common oxidation state for the lanthanide elements is +3.\\n(B) Lanthanide complexes often have high coordination numbers (> 6).\\n(C) All of the lanthanide elements react with aqueous acid to liberate hydrogen.\\n(D) The atomic radii of the lanthanide elements increase across the period from La to Lu.\\nFigure 20: A College Chemistry example.\\n16'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2021-01-13T01:34:15+00:00', 'source': '../data/pdf/example.pdf', 'file_path': '../data/pdf/example.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': 'Measuring Massive Multitask Language Understanding', 'author': 'Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, Jacob Steinhardt', 'subject': 'Deep Learning, Transformers, NLP', 'keywords': 'multitask learning, GPT-3, law, bar exam, few-shot learning, zero-shot, meta-learning', 'moddate': '2021-01-13T01:34:15+00:00', 'trapped': '', 'modDate': 'D:20210113013415Z', 'creationDate': 'D:20210113013415Z', 'page': 16}, page_content='Published as a conference paper at ICLR 2021\\nConsider a computer design in which multiple processors, each with a private cache memory,\\nshare global memory using a single bus. This bus is the critical system resource. Each processor\\ncan execute one instruction every 500 nanoseconds as long as memory references are satisﬁed\\nby its local cache. When a cache miss occurs, the processor is delayed for an additional 2,000\\nnanoseconds. During half of this additional delay, the bus is dedicated to serving the cache miss.\\nDuring the other half, the processor cannot continue, but the bus is free to service requests from\\nother processors. On average, each instruction requires 2 memory references. On average, cache\\nmisses occur on 1 percent of references. What proportion of the capacity of the bus would a single\\nprocessor consume, ignoring delays due to competition from other processors?\\n(A) 1/50\\n(B) 1/27\\n(C) 1/25\\n(D) 2/27\\nFigure 21: A College Computer Science example.\\nLet A be a real 2 × 2 matrix. Which of the following statements must be true?\\nI. All of the entries of A2 are nonnegative.\\nII. The determinant of A2 is nonnegative.\\nIII. If A has two distinct eigenvalues, then A2 has two distinct eigenvalues.\\n(A) I only\\n(B) II only\\n(C) III only\\n(D) II and III only\\nFigure 22: A College Mathematics example.\\nIn a genetic test of a newborn, a rare genetic disorder is found that has X-linked recessive\\ntransmission. Which of the following statements is likely true regarding the pedigree of this\\ndisorder?\\n(A) All descendants on the maternal side will have the disorder.\\n(B) Females will be approximately twice as affected as males in this family.\\n(C) All daughters of an affected male will be affected.\\n(D) There will be equal distribution of males and females affected.\\nFigure 23: A College Medicine example.\\nOne end of a Nichrome wire of length 2L and cross-sectional area A is attached to an end of\\nanother Nichrome wire of length L and cross- sectional area 2A. If the free end of the longer wire\\nis at an electric potential of 8.0 volts, and the free end of the shorter wire is at an electric potential\\nof 1.0 volt, the potential at the junction of the two wires is most nearly equal to\\n(A) 2.4 V\\n(B) 3.3 V\\n(C) 4.5 V\\n(D) 5.7 V\\nFigure 24: A College Physics example.\\nWhy is it that anti-virus scanners would not have found an exploitation of Heartbleed?\\n(A) It’s a vacuous question: Heartbleed only reads outside a buffer, so there is no possible exploit\\n(B) Anti-virus scanners tend to look for viruses and other malicious\\n(C) Heartbleed attacks the anti-virus scanner itself\\n(D) Anti-virus scanners tend to look for viruses and other malicious code, but Heartbleed\\nexploits steal secrets without injecting any code\\nFigure 25: A Computer Security example.\\nA model airplane ﬂies slower when ﬂying into the wind and faster with wind at its back. When\\nlaunched at right angles to the wind, a cross wind, its groundspeed compared with ﬂying in still\\nair is\\n(A) the same\\n(B) greater\\n(C) less\\n(D) either greater or less depending on wind speed\\nFigure 26: A Conceptual Physics example.\\n17'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2021-01-13T01:34:15+00:00', 'source': '../data/pdf/example.pdf', 'file_path': '../data/pdf/example.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': 'Measuring Massive Multitask Language Understanding', 'author': 'Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, Jacob Steinhardt', 'subject': 'Deep Learning, Transformers, NLP', 'keywords': 'multitask learning, GPT-3, law, bar exam, few-shot learning, zero-shot, meta-learning', 'moddate': '2021-01-13T01:34:15+00:00', 'trapped': '', 'modDate': 'D:20210113013415Z', 'creationDate': 'D:20210113013415Z', 'page': 17}, page_content='Published as a conference paper at ICLR 2021\\nConsider the following AR(1) model with the disturbances having zero mean and unit variance\\nyt = 0.2 + 0.4yt−1 + ut\\nThe (unconditional) mean of y will be given by\\n(A) 0.2\\n(B) 0.4\\n(C) 0.5\\n(D) 0.33\\nFigure 27: An Econometrics example.\\nA point pole has a strength of 4π × 10−4 weber. The force in newtons on a point pole of\\n4π × 1.5 × 10−4 weber placed at a distance of 10 cm from it will be\\n(A) 15 N.\\n(B) 20 N.\\n(C) 7.5 N.\\n(D) 3.75 N.\\nFigure 28: An Electrical Engineering example.\\nA total of 30 players will play basketball at a park. There will be exactly 5 players on each team.\\nWhich statement correctly explains how to ﬁnd the number of teams needed?\\n(A) Add 5 to 30 to ﬁnd 35 teams.\\n(B) Divide 30 by 5 to ﬁnd 6 teams.\\n(C) Multiply 30 and 5 to ﬁnd 150 teams.\\n(D) Subtract 5 from 30 to ﬁnd 25 teams.\\nFigure 29: An Elementary Mathematics example.\\nDetermine whether the statements are logically equivalent or contradictory. If neither, determine\\nwhether they are consistent or inconsistent.\\nE ⊃(F · E) and ∼E · F\\n(A) Logically equivalent\\n(B) Contradictory\\n(C) Neither logically equivalent nor contradictory, but consistent\\n(D) Inconsistent\\nFigure 30: A Formal Logic example.\\nAs of 2017, how many of the world’s 1-year-old children today have been vaccinated against\\nsome disease?\\n(A) 80%\\n(B) 60%\\n(C) 40%\\n(D) 20%\\nFigure 31: A Global Facts example.\\nHomologous structures are often cited as evidence for the process of natural selection. All of the\\nfollowing are examples of homologous structures EXCEPT\\n(A) the wings of a bird and the wings of a bat\\n(B) the ﬂippers of a whale and the arms of a man\\n(C) the pectoral ﬁns of a porpoise and the ﬂippers of a seal\\n(D) the forelegs of an insect and the forelimbs of a dog\\nFigure 32: A High School Biology example.\\nFrom the solubility rules, which of the following is true?\\n(A) All chlorides, bromides, and iodides are soluble\\n(B) All sulfates are soluble\\n(C) All hydroxides are soluble\\n(D) All ammonium-containing compounds are soluble\\nFigure 33: A High School Chemistry example.\\n18'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2021-01-13T01:34:15+00:00', 'source': '../data/pdf/example.pdf', 'file_path': '../data/pdf/example.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': 'Measuring Massive Multitask Language Understanding', 'author': 'Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, Jacob Steinhardt', 'subject': 'Deep Learning, Transformers, NLP', 'keywords': 'multitask learning, GPT-3, law, bar exam, few-shot learning, zero-shot, meta-learning', 'moddate': '2021-01-13T01:34:15+00:00', 'trapped': '', 'modDate': 'D:20210113013415Z', 'creationDate': 'D:20210113013415Z', 'page': 18}, page_content='Published as a conference paper at ICLR 2021\\nA list of numbers has n elements, indexed from 1 to n. The following algorithm is intended to\\ndisplay the number of elements in the list that have a value greater than 100. The algorithm uses\\nthe variables count and position. Steps 3 and 4 are missing.\\nStep 1: Set count to 0 and position to 1.\\nStep 2: If the value of the element at index position is greater\\nthan 100, increase the value of count by 1.\\nStep 3: (missing step)\\nStep 4: (missing step)\\nStep 5: Display the value of count.\\nWhich of the following could be used to replace steps 3 and 4 so that the algorithm works as\\nintended?\\n(A) Step 3: Increase the value of position by 1.\\nStep 4: Repeat steps 2 and 3 until the value of count is greater than 100.\\n(B) Step 3: Increase the value of position by 1.\\nStep 4: Repeat steps 2 and 3 until t he value of position is greater than n.\\n(C) Step 3: Repeat step 2 until the value of count is greater than 100.\\nStep 4: Increase the value of position by 1.\\n(D) Step 3: Repeat step 2 until the value of position is greater than n.\\nStep 4: Increase the value of count by 1.\\nFigure 34: A High School Computer Science example.\\nThis question refers to the following information.\\nAlbeit the king’s Majesty justly and rightfully is and ought to be the supreme head of the Church\\nof England, and so is recognized by the clergy of this realm in their convocations, yet nevertheless,\\nfor corroboration and conﬁrmation thereof, and for increase of virtue in Christ’s religion within\\nthis realm of England, and to repress and extirpate all errors, heresies, and other enormities and\\nabuses heretofore used in the same, be it enacted, by authority of this present Parliament, that the\\nking, our sovereign lord, his heirs and successors, kings of this realm, shall be taken, accepted,\\nand reputed the only supreme head in earth of the Church of England, called Anglicans Ecclesia;\\nand shall have and enjoy, annexed and united to the imperial crown of this realm, as well the\\ntitle and style thereof, as all honors, dignities, preeminences, jurisdictions, privileges, authorities,\\nimmunities, proﬁts, and commodities to the said dignity of the supreme head of the same Church\\nbelonging and appertaining; and that our said sovereign lord, his heirs and successors, kings of\\nthis realm, shall have full power and authority from time to time to visit, repress, redress, record,\\norder, correct, restrain, and amend all such errors, heresies, abuses, offenses, contempts, and\\nenormities, whatsoever they be, which by any manner of spiritual authority or jurisdiction ought\\nor may lawfully be reformed, repressed, ordered, redressed, corrected, restrained, or amended,\\nmost to the pleasure of Almighty God, the increase of virtue in Christ’s religion, and for the\\nconservation of the peace, unity, and tranquility of this realm; any usage, foreign land, foreign\\nauthority, prescription, or any other thing or things to the contrary hereof notwithstanding.\\nEnglish Parliament, Act of Supremacy, 1534\\nFrom the passage, one may infer that the English Parliament wished to argue that the Act of\\nSupremacy would\\n(A) give the English king a new position of authority\\n(B) give the position of head of the Church of England to Henry VIII alone and exclude his heirs\\n(C) establish Calvinism as the one true theology in England\\n(D) end various forms of corruption plaguing the Church in England\\nFigure 35: A High School European History example.\\nDuring the third stage of the demographic transition model, which of the following is true?\\n(A) Birth rates increase and population growth rate is less rapid.\\n(B) Birth rates decline and population growth rate is less rapid.\\n(C) Birth rates increase and population growth rate increases.\\n(D) Birth rates decrease and population growth rate increases.\\nFigure 36: A High School Geography example.\\n19'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2021-01-13T01:34:15+00:00', 'source': '../data/pdf/example.pdf', 'file_path': '../data/pdf/example.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': 'Measuring Massive Multitask Language Understanding', 'author': 'Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, Jacob Steinhardt', 'subject': 'Deep Learning, Transformers, NLP', 'keywords': 'multitask learning, GPT-3, law, bar exam, few-shot learning, zero-shot, meta-learning', 'moddate': '2021-01-13T01:34:15+00:00', 'trapped': '', 'modDate': 'D:20210113013415Z', 'creationDate': 'D:20210113013415Z', 'page': 19}, page_content='Published as a conference paper at ICLR 2021\\nWhich of the following best states an argument made by James Madison in The Federalist number\\n10?\\n(A) Honest politicians can prevent factions from developing.\\n(B) Factions are more likely to occur in large republics than in small ones.\\n(C) The negative effects of factionalism can be reduced by a republican government.\\n(D) Free elections are the people’s best defense against factionalism.\\nFigure 37: A High School Government and Politics example.\\nWhich of the following is not included in the U.S. GDP?\\n(A) The U.S. military opens a new base in a foreign country with 1000 U.S. personnel.\\n(B) Japanese consumers buy thousands of CDs produced in the United States.\\n(C) An American pop singer performs a sold-out concert in Paris.\\n(D) A French theatrical production tours dozens of American cities.\\nFigure 38: A High School Macroeconomics example.\\nJoe was in charge of lights for a dance. The red light blinks every two seconds, the yellow light\\nevery three seconds, and the blue light every ﬁve seconds. If we include the very beginning and\\nvery end of the dance, how many times during a seven minute dance will all the lights come on at\\nthe same time? (Assume that all three lights blink simultaneously at the very beginning of the\\ndance.)\\n(A) 3\\n(B) 15\\n(C) 6\\n(D) 5\\nFigure 39: A High School Mathematics example.\\nIf the government subsidizes producers in a perfectly competitive market, then\\n(A) the demand for the product will increase\\n(B) the demand for the product will decrease\\n(C) the consumer surplus will increase\\n(D) the consumer surplus will decrease\\nFigure 40: A High School Microeconomics example.\\nA point charge, Q = +1 mC, is ﬁxed at the origin. How much work is required to move a charge,\\nQ = +8 µC, from the point (0, 4 meters) to the point (3 meters, 0)?\\n(A) 3.5 J\\n(B) 6.0 J\\n(C) 22.5 J\\n(D) 40 J\\nFigure 41: A High School Physics example.\\nWhile swimming in the ocean, Ivan is frightened by a dark shadow in the water even before he\\nhas the chance to identify what the shadow is. The synaptic connections taking place during this\\nincident of fright are best described by which of the following?\\n(A) Messages are sent from the thalamus directly to the amygdala.\\n(B) Messages are sent from the thalamus to the “what” and “where” pathways.\\n(C) Messages are sent from the parasympathetic nervous system to the cerebral cortex.\\n(D) Messages are sent from the frontal lobes to the pituitary gland.\\nFigure 42: A High School Psychology example.\\n20'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2021-01-13T01:34:15+00:00', 'source': '../data/pdf/example.pdf', 'file_path': '../data/pdf/example.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': 'Measuring Massive Multitask Language Understanding', 'author': 'Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, Jacob Steinhardt', 'subject': 'Deep Learning, Transformers, NLP', 'keywords': 'multitask learning, GPT-3, law, bar exam, few-shot learning, zero-shot, meta-learning', 'moddate': '2021-01-13T01:34:15+00:00', 'trapped': '', 'modDate': 'D:20210113013415Z', 'creationDate': 'D:20210113013415Z', 'page': 20}, page_content='Published as a conference paper at ICLR 2021\\nJonathan obtained a score of 80 on a statistics exam, placing him at the 90th percentile. Suppose\\nﬁve points are added to everyone’s score. Jonathan’s new score will be at the\\n(A) 80th percentile.\\n(B) 85th percentile.\\n(C) 90th percentile.\\n(D) 95th percentile.\\nFigure 43: A High School Statistics example.\\nThis question refers to the following information.\\n“Society in every state is a blessing, but government even in its best state is but a necessary evil; in\\nits worst state an intolerable one; for when we suffer, or are exposed to the same miseries by a\\ngovernment, which we might expect in a country without government, our calamity is heightened\\nby reﬂecting that we furnish the means by which we suffer. Government, like dress, is the badge\\nof lost innocence; the palaces of kings are built on the ruins of the bowers of paradise. For were\\nthe impulses of conscience clear, uniform, and irresistibly obeyed, man would need no other\\nlawgiver; but that not being the case, he ﬁnds it necessary to surrender up a part of his property to\\nfurnish means for the protection of the rest; and this he is induced to do by the same prudence\\nwhich in every other case advises him out of two evils to choose the least. Wherefore, security\\nbeing the true design and end of government, it unanswerably follows that whatever form thereof\\nappears most likely to ensure it to us, with the least expense and greatest beneﬁt, is preferable to\\nall others.”\\nThomas Paine, Common Sense, 1776\\nWhich of the following “miseries” alluded to above were most condemned by Anti-Federalists of\\nthe post-Revolutionary era?\\n(A) Organized response to Bacon’s Rebellion.\\n(B) Federal response to Shays’s Rebellion.\\n(C) Federal response to the Whiskey Rebellion.\\n(D) Federal response to Pontiac’s Rebellion.\\nFigure 44: A High School US History example.\\nThis question refers to the following information.\\n“The real grievance of the worker is the insecurity of his existence; he is not sure that he will\\nalways have work, he is not sure that he will always be healthy, and he foresees that he will one\\nday be old and unﬁt to work. If he falls into poverty, even if only through a prolonged illness, he\\nis then completely helpless, left to his own devices, and society does not currently recognize any\\nreal obligation towards him beyond the usual help for the poor, even if he has been working all\\nthe time ever so faithfully and diligently. The usual help for the poor, however, leaves a lot to be\\ndesired, especially in large cities, where it is very much worse than in the country.”\\nOtto von Bismarck, 1884\\nOtto von Bismarck likely made this speech in reaction to which of the following issues?\\n(A) Social acceptance of child labor.\\n(B) Declining life expectancy in Germany.\\n(C) Criticisms of German trade tariffs.\\n(D) Negative effects attributed to industrial capitalism.\\nFigure 45: A High School World History example.\\nAll other things being equal, which of the following persons is more likely to show osteoporosis?\\n(A) An older Hispanic American woman\\n(B) An older African American woman\\n(C) An older Asian American woman\\n(D) An older Native American woman\\nFigure 46: A Human Aging example.\\n21'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2021-01-13T01:34:15+00:00', 'source': '../data/pdf/example.pdf', 'file_path': '../data/pdf/example.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': 'Measuring Massive Multitask Language Understanding', 'author': 'Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, Jacob Steinhardt', 'subject': 'Deep Learning, Transformers, NLP', 'keywords': 'multitask learning, GPT-3, law, bar exam, few-shot learning, zero-shot, meta-learning', 'moddate': '2021-01-13T01:34:15+00:00', 'trapped': '', 'modDate': 'D:20210113013415Z', 'creationDate': 'D:20210113013415Z', 'page': 21}, page_content='Published as a conference paper at ICLR 2021\\nMorning sickness is typically a problem:\\n(A) during the ﬁrst trimester\\n(B) during the second trimester\\n(C) during the third trimester\\n(D) all through the pregnancy\\nFigure 47: A Human Sexuality example.\\nWould a reservation to the deﬁnition of torture in the ICCPR be acceptable in contemporary\\npractice?\\n(A) This is an acceptable reservation if the reserving country’s legislation employs a different\\ndeﬁnition\\n(B) This is an unacceptable reservation because it contravenes the object and purpose of\\nthe ICCPR\\n(C) This is an unacceptable reservation because the deﬁnition of torture in the ICCPR is consistent\\nwith customary international law\\n(D) This is an acceptable reservation because under general international law States have the right\\nto enter reservations to treaties\\nFigure 48: An International Law example.\\nWhich position does Rawls claim is the least likely to be adopted by the POP (people in the\\noriginal position)?\\n(A) The POP would choose equality above liberty.\\n(B) The POP would opt for the ‘maximin’ strategy.\\n(C) The POP would opt for the ‘difference principle.’\\n(D) The POP would reject the ‘system of natural liberty.’\\nFigure 49: A Jurisprudence example.\\nJohn Stuart Mill: Each person’s happiness is a good to that person, and the general happiness,\\ntherefore, a good to the aggregate of all persons.\\n(A) Fallacy of Composition\\n(B) Fallacy of Division\\n(C) Gambler’s Fallacy\\n(D) Equivocation\\nFigure 50: A Logical Fallacies example.\\nA 6-sided die is rolled 15 times and the results are: side 1 comes up 0 times; side 2: 1 time; side\\n3: 2 times; side 4: 3 times; side 5: 4 times; side 6: 5 times. Based on these results, what is the\\nprobability of side 3 coming up when using Add-1 Smoothing?\\n(A) 2/15\\n(B) 1/7\\n(C) 3/16\\n(D) 1/5\\nFigure 51: A Machine Learning example.\\nAccording to Lewin, Lippet and White’s 1939 experiment, which form of leadership produced the\\nmost work from participants?\\n(A) Laissez-faire\\n(B) Democratic\\n(C) Authoritarian\\n(D) A mix of laissez-faire and democratic\\nFigure 52: A Management example.\\n22'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2021-01-13T01:34:15+00:00', 'source': '../data/pdf/example.pdf', 'file_path': '../data/pdf/example.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': 'Measuring Massive Multitask Language Understanding', 'author': 'Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, Jacob Steinhardt', 'subject': 'Deep Learning, Transformers, NLP', 'keywords': 'multitask learning, GPT-3, law, bar exam, few-shot learning, zero-shot, meta-learning', 'moddate': '2021-01-13T01:34:15+00:00', 'trapped': '', 'modDate': 'D:20210113013415Z', 'creationDate': 'D:20210113013415Z', 'page': 22}, page_content='Published as a conference paper at ICLR 2021\\nThe single group within society that is most vulnerable to reference group inﬂuence is:\\n(A) The older consumer who feels somewhat left out of things.\\n(B) The married women, many of whom feel a need for stability in their lives.\\n(C) New immigrants who really want to assimilate into their new culture.\\n(D) Children, who base most of their buying decisions on outside inﬂuences.\\nFigure 53: A Marketing example.\\nWhich of the following conditions does not show multifactorial inheritance?\\n(A) Pyloric stenosis\\n(B) Schizophrenia\\n(C) Spina biﬁda (neural tube defects)\\n(D) Marfan syndrome\\nFigure 54: A Medical Genetics example.\\nIf each of the following meals provides the same number of calories, which meal requires the\\nmost land to produce the food?\\n(A) Red beans and rice\\n(B) Steak and a baked potato\\n(C) Corn tortilla and refried beans\\n(D) Lentil soup and brown bread\\nFigure 55: A Miscellaneous example.\\nIn response to Sandel’s “social justice” argument, Kamm argues that\\n(A) even if we were able to enhance ourselves or others, we would not thereby be obligated to do\\nso.\\n(B) there is a difference between (i) choosing that one have a certain trait and (ii) being responsible\\nfor bearing the costs of that choice.\\n(C) having the option to enhance will lead to fewer instances of people who require the assistance\\nof others.\\n(D) all of the above\\nFigure 56: A Moral Disputes example.\\nFor which of these two scenarios does the main character (who uses I/me/my) do something\\nclearly morally wrong?\\nScenario 1 | I drive very fast when I’m on a racetrack.\\nScenario 2 | I drive very fast when I’m in the suburbs.\\n(A) Wrong, Wrong\\n(B) Wrong, Not wrong\\n(C) Not wrong, Wrong\\n(D) Not wrong, Not wrong\\nFigure 57: A Moral Scenarios example. The formatting of this task hinders UniﬁedQA performance\\nsubstantially.\\nWhich of the following is the most plausible explanation for the protective effect of dietary ﬁbre\\nagainst cancer of the colon?\\n(A) Propionic acid, formed during colonic ﬁbre fermentation inhibits liver fatty acid synthesis\\n(B) Butyric acid, formed during colonic ﬁbre fermentation stimulates \"silencing\" of the SLC5A8\\ntumour suppressor gene\\n(C) Butyric acid, formed during colonic ﬁbre fermentation stimulates anti-oxidant defences\\nin the colon\\n(D) None of these options are correct\\nFigure 58: A Nutrition example.\\n23'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2021-01-13T01:34:15+00:00', 'source': '../data/pdf/example.pdf', 'file_path': '../data/pdf/example.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': 'Measuring Massive Multitask Language Understanding', 'author': 'Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, Jacob Steinhardt', 'subject': 'Deep Learning, Transformers, NLP', 'keywords': 'multitask learning, GPT-3, law, bar exam, few-shot learning, zero-shot, meta-learning', 'moddate': '2021-01-13T01:34:15+00:00', 'trapped': '', 'modDate': 'D:20210113013415Z', 'creationDate': 'D:20210113013415Z', 'page': 23}, page_content='Published as a conference paper at ICLR 2021\\nAccording to Moore’s “ideal utilitarianism,” the right action is the one that brings about the\\ngreatest amount of:\\n(A) pleasure.\\n(B) happiness.\\n(C) good.\\n(D) virtue.\\nFigure 59: A Philosophy example.\\nResearchers now believe that the decline of the Maya was caused chieﬂy by:\\n(A) a cataclysm of some kind, such as an earthquake, volcano, or tsunami.\\n(B) ecological degradation resulting from slash-and-burn farming techniques.\\n(C) endless wars between neighboring Mayan city-states.\\n(D) practices of interbreeding that led to a steep rise in congenital disorders.\\nFigure 60: A Prehistory example.\\nKrete is an unmarried taxpayer with income exclusively from wages. By December 31, year 1,\\nKrete’s employer has withheld $16,000 in federal income taxes and Krete has made no estimated\\ntax payments. On April 15, year 2, Krete timely ﬁled for an extension request to ﬁle her individual\\ntax return, and paid $300 of additional taxes. Krete’s year 1 tax liability was $16,500 when she\\ntimely ﬁled her return on April 30, year 2, and paid the remaining tax liability balance. What\\namount would be subject to the penalty for underpayment of estimated taxes?\\n(A) $0\\n(B) $500\\n(C) $1,650\\n(D) $16,500\\nFigure 61: A Professional Accounting example.\\nThe night before his bar examination, the examinee’s next-door neighbor was having a party. The\\nmusic from the neighbor’s home was so loud that the examinee couldn’t fall asleep. The examinee\\ncalled the neighbor and asked her to please keep the noise down. The neighbor then abruptly hung\\nup. Angered, the examinee went into his closet and got a gun. He went outside and ﬁred a bullet\\nthrough the neighbor’s living room window. Not intending to shoot anyone, the examinee ﬁred\\nhis gun at such an angle that the bullet would hit the ceiling. He merely wanted to cause some\\ndamage to the neighbor’s home to relieve his angry rage. The bullet, however, ricocheted off the\\nceiling and struck a partygoer in the back, killing him. The jurisdiction makes it a misdemeanor\\nto discharge a ﬁrearm in public. The examinee will most likely be found guilty for which of the\\nfollowing crimes in connection to the death of the partygoer?\\n(A) Murder.\\n(B) Involuntary manslaughter.\\n(C) Voluntary manslaughter.\\n(D) Discharge of a ﬁrearm in public.\\nFigure 62: A Professional Law example.\\n24'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2021-01-13T01:34:15+00:00', 'source': '../data/pdf/example.pdf', 'file_path': '../data/pdf/example.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': 'Measuring Massive Multitask Language Understanding', 'author': 'Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, Jacob Steinhardt', 'subject': 'Deep Learning, Transformers, NLP', 'keywords': 'multitask learning, GPT-3, law, bar exam, few-shot learning, zero-shot, meta-learning', 'moddate': '2021-01-13T01:34:15+00:00', 'trapped': '', 'modDate': 'D:20210113013415Z', 'creationDate': 'D:20210113013415Z', 'page': 24}, page_content='Published as a conference paper at ICLR 2021\\nA 63-year-old man is brought to the emergency department because of a 4-day history of in-\\ncreasingly severe left leg pain and swelling of his left calf. He also has a 1-month history of\\nincreasingly severe upper midthoracic back pain. During this time, he has had a 9-kg (20-lb)\\nweight loss despite no change in appetite. He has no history of major medical illness. His only\\nmedication is ibuprofen. He is 180 cm (5 ft 11 in) tall and weighs 82 kg (180 lb); BMI is 25\\nkg/m2 . His vital signs are within normal limits. On examination, lower extremity pulses are\\npalpable bilaterally. The remainder of the physical examination shows no abnormalities. An x-ray\\nof the thoracic spine shows no abnormalities. A CT scan of the abdomen shows a 3-cm mass in\\nthe body of the pancreas; there are liver metastases and encasement of the superior mesenteric\\nartery. Ultrasonography of the left lower extremity shows a femoropopliteal venous clot. Which\\nof the following is the most likely cause of this patient’s symptoms?\\n(A) Carcinoid syndrome\\n(B) Hypercoagulability from advanced malignancy\\n(C) Multiple endocrine neoplasia\\n(D) Splenic artery aneurysm and embolic disease of the left lower extremity\\nFigure 63: A Professional Medicine example.\\nThe technique that is most likely to produce an immediate improvement in the behavior of a child\\nwho hits others and rips up schoolbooks is\\n(A) a combination of reinforcement for appropriate behavior and mild punishment for in-\\nappropriate behavior\\n(B) differential positive reinforcement\\n(C) loss of privileges for misbehaving\\n(D) shaping\\nFigure 64: A Professional Psychology example.\\nYou work for a utility company that is building a biomass plant in the community. Your employer\\nasks you to give a series of community talks about the plant and future operations. You visit the\\nplant several hours before you are due to give a speech that has been prepared by your immediate\\nsupervisor. During the tour of the plant, you discover several claims in the speech are not true.\\nWhat do you do?\\n(A) Write and deliver a new speech that you know is entirely correct.\\n(B) Cancel all speeches until you and your supervisor can get the information straight.\\n(C) Deliver the speech as prepared and discuss the inaccuracies with your supervisor afterward.\\n(D) Address the inaccuracies with your supervisor immediately and make the necessary\\ncorrections before giving the speech.\\nFigure 65: A Public Relations example.\\n25'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2021-01-13T01:34:15+00:00', 'source': '../data/pdf/example.pdf', 'file_path': '../data/pdf/example.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': 'Measuring Massive Multitask Language Understanding', 'author': 'Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, Jacob Steinhardt', 'subject': 'Deep Learning, Transformers, NLP', 'keywords': 'multitask learning, GPT-3, law, bar exam, few-shot learning, zero-shot, meta-learning', 'moddate': '2021-01-13T01:34:15+00:00', 'trapped': '', 'modDate': 'D:20210113013415Z', 'creationDate': 'D:20210113013415Z', 'page': 25}, page_content='Published as a conference paper at ICLR 2021\\nThe Chemical Weapons Convention (CWC) prohibited the possession or deployment of chemical\\nweapons; however it failed to implement stipulations that would require signatories to declare their\\nexisting stocks of chemical weapons, to identify facilities that were once involved in chemical\\nproduction, or to announce when their existing stocks would be destroyed.\\n(A) The Chemical Weapons Convention (CWC) prohibited the possession or deployment of\\nchemical weapons; however it failed to implement stipulations that would require signatories to\\ndeclare their existing stocks of chemical weapons, to identify facilities that were once involved in\\nchemical production, or to announce when their existing stocks would be destroyed.\\n(B) The CWC made some important developments regarding the use and possession of chemical\\nweapons and the destruction of existing stockpiles. However, the treaty failed to establish an\\nindependent body empowered with the capacity to check treaty compliance. Lack of supra-state\\nauthority has undermined the ability to enforce those developments. Given the anarchical nature\\nof international society it may be in the national security interest to retain stocks.\\n(C) Chemical weapons continue to exert a determining inﬂuence on international society. As early\\nas the 1970s military strategists were convinced of the deterrence effects chemical weapons could\\nhave, comparable to the second strike survival logic of nuclear deterrence. The preferences of\\nstrategists resulted in continued manufacture and stockpiling of weapons creating an international\\ncrisis of stability.\\n(D) While the CWC has been ratiﬁed by the majority of international society, some nations\\nwith a large chemical capability at their disposal have yet to enter into the treaty. However,\\nto some analysts the destructive military potential would be limited, having a moderate\\neffect on a well-equipped army in conventional warfare. Chemical arsenal essentially falls\\nunder the category of the \"poor mans\" weaponry, being simplistic and inexpensive whilst\\nhaving limited military utility. However, the concern remains of the prospective impact a\\nterrorist chemical attack could have on civilian populations.\\nFigure 66: A Security Studies example.\\nWhich of the following statements most closely corresponds with differential association theory?\\n(A) If all of your friends jumped off a bridge, I suppose you would too.\\n(B) You should be proud to be a part of this organization.\\n(C) If the door is closed, try the window.\\n(D) Once a thief, always a thief.\\nFigure 67: A Sociology example.\\nWhy did Congress oppose Wilson’s proposal for the League of Nations?\\n(A) It feared the League would encourage Soviet inﬂuence in the US\\n(B) It feared the League would be anti-democratic\\n(C) It feared the League would commit the US to an international alliance\\n(D) Both a and b\\nFigure 68: A US Foreign Policy example.\\nAn observational study in diabetics assesses the role of an increased plasma ﬁbrinogen level on\\nthe risk of cardiac events. 130 diabetic patients are followed for 5 years to assess the development\\nof acute coronary syndrome. In the group of 60 patients with a normal baseline plasma ﬁbrinogen\\nlevel, 20 develop acute coronary syndrome and 40 do not. In the group of 70 patients with a high\\nbaseline plasma ﬁbrinogen level, 40 develop acute coronary syndrome and 30 do not. Which of\\nthe following is the best estimate of relative risk in patients with a high baseline plasma ﬁbrinogen\\nlevel compared to patients with a normal baseline plasma ﬁbrinogen level?\\n(A) (40/30)/(20/40)\\n(B) (40*40)/(20*30)\\n(C) (40*70)/(20*60)\\n(D) (40/70)/(20/60)\\nFigure 69: A Virology example.\\n26'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2021-01-13T01:34:15+00:00', 'source': '../data/pdf/example.pdf', 'file_path': '../data/pdf/example.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': 'Measuring Massive Multitask Language Understanding', 'author': 'Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, Jacob Steinhardt', 'subject': 'Deep Learning, Transformers, NLP', 'keywords': 'multitask learning, GPT-3, law, bar exam, few-shot learning, zero-shot, meta-learning', 'moddate': '2021-01-13T01:34:15+00:00', 'trapped': '', 'modDate': 'D:20210113013415Z', 'creationDate': 'D:20210113013415Z', 'page': 26}, page_content='Published as a conference paper at ICLR 2021\\nThe Great Cloud Sutra prophesied the imminent arrival of which person?\\n(A) Maitreya (Milo)\\n(B) The Buddha\\n(C) Zhou Dunyi\\n(D) Wang Yangming\\nFigure 70: A World Religions example.\\n27')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### PDF Loader\n",
    "from langchain_community.document_loaders import PyPDFLoader, PyMuPDFLoader\n",
    "\n",
    "## load all the text files from the directory\n",
    "dir_loader=DirectoryLoader(\n",
    "    \"../data/pdf\",\n",
    "    glob=\"**/*.pdf\", ## Pattern to match files  \n",
    "    loader_cls= PyMuPDFLoader, ##loader class to use (pdf should be PDFLoader)\n",
    "    show_progress=False\n",
    "\n",
    ")\n",
    "\n",
    "pdf_documents=dir_loader.load()\n",
    "pdf_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.documents.base.Document"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(pdf_documents[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding and VectorStoreDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EmbeddingManager -> for turning text into vectors\n",
    "VectorStore -> for storing those vectors and retrieving them later by similarity search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "import uuid # for generating unique IDs\n",
    "from typing import List, Dict, Any, Tuple\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embedding model: all-MiniLM-L6-v2\n",
      "Model loaded successfully. Embedding dimension: 384\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.EmbeddingManager at 0x1d8a256d0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Notes\n",
    "    # self.model = SentenceTransformer(self.model_name) # we are loading this model\n",
    "    # self.model.get_sentence_embedding_dimension() # 384 --> The model all-MiniLM-L6-v2 transforms text into a point in 384-dimensional space\n",
    "        # Higher dimension captures more semantic nuance\n",
    "        # Lower dimension is faster and cheaper to store and search\n",
    "        # 384-dimensional = vector length is 384 -> Each embedding is a vector containing 384 numerical values\n",
    "    # embeddings = self.model.encode(texts, show_progress_bar=True) # generate embeddings for the text\n",
    "\n",
    "class EmbeddingManager:\n",
    "    \"\"\"Handles document embedding generation using SentenceTransformer\"\"\"\n",
    "    \n",
    "    def __init__(self, model_name: str = \"all-MiniLM-L6-v2\"): # all-MiniLM-L6-v2 is for text->vectors\n",
    "        \"\"\"\n",
    "        Initialize the embedding manager\n",
    "        \n",
    "        Args:\n",
    "            model_name: HuggingFace model name for sentence embeddings\n",
    "        \"\"\"\n",
    "        self.model_name = model_name\n",
    "        self.model = None\n",
    "        self._load_model() # load the model once during initialization\n",
    "    \n",
    "    def _load_model(self):\n",
    "        \"\"\"Load the SentenceTransformer model\"\"\"\n",
    "        try:\n",
    "            print(f\"Loading embedding model: {self.model_name}\")\n",
    "            self.model = SentenceTransformer(self.model_name) # we are loading this model\n",
    "            print(f\"Model loaded successfully. Embedding dimension: {self.model.get_sentence_embedding_dimension()}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading model {self.model_name}: {e}\")\n",
    "            raise\n",
    "\n",
    "    def generate_embeddings(self, texts: List[str]) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Generate embeddings for a list of texts\n",
    "        \n",
    "        Args:\n",
    "            texts: List of text strings to embed\n",
    "            \n",
    "        Returns:\n",
    "            numpy array of embeddings with shape (len(texts), embedding_dim)\n",
    "        \"\"\"\n",
    "        if not self.model:\n",
    "            raise ValueError(\"Model not loaded\")\n",
    "        \n",
    "        print(f\"Generating embeddings for {len(texts)} texts...\")\n",
    "        embeddings = self.model.encode(texts, show_progress_bar=True)\n",
    "        print(f\"Generated embeddings with shape: {embeddings.shape}\")\n",
    "        return embeddings\n",
    "    \n",
    "    # Not required \n",
    "    def get_embedding_dimension(self) -> int:\n",
    "        \"\"\"Get the dimension of the embeddings\"\"\"\n",
    "        if not self.model:\n",
    "            raise ValueError(\"Model not loaded\")\n",
    "        return self.model.get_sentence_embedding_dimension()\n",
    "\n",
    "## Initialize the embedding manager\n",
    "\n",
    "embedding_manager=EmbeddingManager()\n",
    "embedding_manager"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VectorStore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VectorStore:\n",
    "    \"\"\"Manages document embeddings in a ChromaDB vector store\"\"\"\n",
    "    \n",
    "    def __init__(self, collection_name: str = \"pdf_documents\", persist_directory: str = \"../data/vector_store\"):\n",
    "        # collection_name = Store all vectors for my PDF documents in a collection called pdf_documents\n",
    "        # persistent_directory = Save the database files to this folder on disk -> restart and embeddings are still there\n",
    "        \"\"\"\n",
    "        Initialize the vector store\n",
    "        \n",
    "        Args:\n",
    "            collection_name: Name of the ChromaDB collection\n",
    "            persist_directory: Directory to persist the vector store\n",
    "        \"\"\"\n",
    "        self.collection_name = collection_name\n",
    "        self.persist_directory = persist_directory\n",
    "        self.client = None\n",
    "        self.collection = None\n",
    "        self._initialize_store()\n",
    "\n",
    "    def _initialize_store(self):\n",
    "        \"\"\"Initialize ChromaDB client and collection\"\"\"\n",
    "        try:\n",
    "            # Create persistent ChromaDB client\n",
    "            os.makedirs(self.persist_directory, exist_ok=True)\n",
    "            self.client = chromadb.PersistentClient(path=self.persist_directory)\n",
    "            \n",
    "            # Get or create collection\n",
    "            self.collection = self.client.get_or_create_collection(\n",
    "                name=self.collection_name,\n",
    "                metadata={\"description\": \"PDF document embeddings for RAG\"}\n",
    "            )\n",
    "            print(f\"Vector store initialized. Collection: {self.collection_name}\")\n",
    "            print(f\"Existing documents in collection: {self.collection.count()}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error initializing vector store: {e}\")\n",
    "            raise\n",
    "\n",
    "    def add_documents(self, documents: List[Any], embeddings: np.ndarray):\n",
    "        \"\"\"\n",
    "        Add documents and their embeddings to the vector store\n",
    "        \n",
    "        Args:\n",
    "            documents: List of LangChain documents\n",
    "            embeddings: Corresponding embeddings for the documents\n",
    "        \"\"\"\n",
    "        if len(documents) != len(embeddings):\n",
    "            raise ValueError(\"Number of documents must match number of embeddings\")\n",
    "        \n",
    "        print(f\"Adding {len(documents)} documents to vector store...\")\n",
    "        \n",
    "        # Prepare data for ChromaDB\n",
    "        ids = []\n",
    "        metadatas = []\n",
    "        documents_text = []\n",
    "        embeddings_list = []\n",
    "        \n",
    "        for i, (doc, embedding) in enumerate(zip(documents, embeddings)):\n",
    "            # Generate unique ID\n",
    "            doc_id = f\"doc_{uuid.uuid4().hex[:8]}_{i}\"\n",
    "            ids.append(doc_id)\n",
    "            \n",
    "            # Prepare metadata\n",
    "            metadata = dict(doc.metadata)\n",
    "            metadata['doc_index'] = i\n",
    "            metadata['content_length'] = len(doc.page_content)\n",
    "            metadatas.append(metadata)\n",
    "            \n",
    "            # Document content\n",
    "            documents_text.append(doc.page_content)\n",
    "            \n",
    "            # Embedding\n",
    "            embeddings_list.append(embedding.tolist())\n",
    "        \n",
    "        # Add to collection\n",
    "        try:\n",
    "            self.collection.add(\n",
    "                ids=ids,\n",
    "                embeddings=embeddings_list,\n",
    "                metadatas=metadatas,\n",
    "                documents=documents_text\n",
    "            )\n",
    "            print(f\"Successfully added {len(documents)} documents to vector store\")\n",
    "            print(f\"Total documents in collection: {self.collection.count()}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error adding documents to vector store: {e}\")\n",
    "            raise\n",
    "\n",
    "vectorstore=VectorStore()\n",
    "vectorstore\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
